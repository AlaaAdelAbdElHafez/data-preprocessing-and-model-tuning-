{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "üåà The format of the input file (SDF file) is a chemical structure file format used to represent molecular structures. It typically contains information such as atom types, bond types, and 3D coordinates of atoms.\n",
        "\n",
        "üåà The input tensors to the neural network model are:\n",
        "   - `data`: Represents the node features or properties of the molecular structures. Its shape is `(batch_size, features)`, where `batch_size` is the number of samples in the batch, and `features` represents the number of features or properties for each node.\n",
        "   - `edges`: Represents the edges or connections between nodes. Its shape is `(batch_size, max_edges, 2)`, where `max_edges` is the maximum number of edges in any graph in the batch, and `2` represents the two nodes connected by each edge.\n",
        "   - `node2graph`: Represents the mapping of nodes to their respective graphs. Its shape is `(batch_size,)`, where each element represents the graph index for the corresponding node in the `data` tensor.\n",
        "\n",
        "üåà For `gnn_out`, each dimension likely symbolizes:\n",
        "   - First dimension: Represents the batch size or the number of graphs.\n",
        "   - Second dimension: Represents the number of nodes in each graph.\n",
        "   - Third dimension: Represents the hidden feature dimension or the output dimension of the GCN layer.\n",
        "   \n",
        "   For `avg`, each dimension likely symbolizes:\n",
        "   - First dimension: Represents the batch size or the number of graphs.\n",
        "   - Second dimension: Represents the hidden feature dimension or the output dimension of the GCN layer after averaging over nodes in each graph.\n",
        "\n",
        "üåà `segment_mean` calculates the mean along segments, where the segments are defined by `segment_ids`. It calculates the mean of elements with the same segment ID. On the other hand, `tf.reduce_mean` calculates the mean across all elements in the input tensor. For `pred`, each dimension likely symbolizes:\n",
        "   - First dimension: Represents the batch size or the number of samples.\n",
        "   - Second dimension: Represents the output dimension of the neural network model, typically representing the predicted probability for each sample.\n",
        "\n",
        "üåà The motivation to use multiple GCN layers is to capture hierarchical and complex relationships within the graph structure. Each GCN layer can extract increasingly abstract and high-level features from the input graph. The depth of the network allows for more sophisticated feature learning and representation. In the template, multiple GCN layers were used, although the exact number was not specified.\n",
        "\n",
        "‚úîÔ∏è **Problem Formulation:**\n",
        "The problem involves predicting the anticancer activity of chemical compounds against non-small cell lung cancer based on their molecular structures represented as graphs. Each chemical compound is inputted as a graph, where atoms represent nodes and bonds represent edges. The output is binary, indicating whether a compound is positive (effective against cancer) or negative (not effective against cancer). The task requires a classification function to predict the binary outcome. Challenges may include handling the complexity of molecular structures, capturing subtle features that contribute to anticancer activity, and dealing with imbalanced datasets. The impact of accurately predicting anticancer activity is significant, as it can aid in drug discovery and development, potentially leading to new treatments for cancer. An ideal solution would be a neural network model capable of effectively learning features from molecular graphs and making accurate predictions based on those features. This model should be robust, interpretable, and generalizable to unseen chemical compounds. Additionally, it should handle imbalanced data and provide insights into the molecular features contributing to anticancer activity."
      ],
      "metadata": {
        "id": "-9BzPOm0pMe-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiMsfc0PBu47"
      },
      "source": [
        "## Read SDF format data (structured-data format)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python code defines a function named `read_sdf` that reads content from a file, parses it into samples, and extracts information about nodes, links, and labels from each sample. Here's a breakdown of what the code does:\n",
        "\n",
        "1. The code imports the `numpy` library and aliases it as `np`. It also imports the `tqdm` library from the `notebook` submodule, which is used to display progress bars for iterative processes.\n",
        "\n",
        "2. The `read_sdf` function takes a file parameter as input.\n",
        "\n",
        "3. Within the function:\n",
        "   - The file is opened and its content is read.\n",
        "   - The content is split into samples based on the delimiter \"$$$$\".\n",
        "   - A nested function named `parse_sample` is defined to process each sample.\n",
        "   - Each sample is split into lines, and information about nodes, links, and labels is extracted from each line.\n",
        "   - For each line in the sample:\n",
        "     - If the line contains '1.0', the label is set to 1.\n",
        "     - If the line contains '-1.0', the label is set to 0.\n",
        "     - If the line starts with four spaces, node information is extracted and appended to a list of nodes.\n",
        "     - If the line starts with a single space, information about edges (links) is extracted and appended to a list of links.\n",
        "   - The function returns a tuple containing lists of nodes, links (as numpy arrays), and the label.\n",
        "\n",
        "4. Finally, the `read_sdf` function returns a list comprehension that applies the `parse_sample` function to each sample, using tqdm to display a progress bar. Samples with a length greater than 0 are included in the final list.\n",
        "\n"
      ],
      "metadata": {
        "id": "A0acUwsoaTfy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad4OadhQBu5K"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # Importing the numpy library and aliasing it as np\n",
        "from tqdm.notebook import tqdm  # Importing the tqdm library for progress bar display\n",
        "\n",
        "def read_sdf(file):  # Defining a function named read_sdf that takes a file parameter\n",
        "    with open(file, 'r') as rf:  # Opening the file in read mode\n",
        "        content = rf.read()  # Reading the content of the file\n",
        "    samples = content.split('$$$$')  # Splitting the content into samples based on '$$$$'\n",
        "\n",
        "    def parse_sample(s):  # Defining a nested function named parse_sample that takes a sample parameter\n",
        "        lines = s.splitlines()  # Splitting the sample into lines\n",
        "        links = []  # Initializing an empty list to store links\n",
        "        nodes = []  # Initializing an empty list to store nodes\n",
        "        label = 0  # Initializing label variable\n",
        "        for l in lines:  # Iterating through lines in the sample\n",
        "            if l.strip() == '1.0':  # Checking if line contains '1.0'\n",
        "                label = 1  # Setting label to 1\n",
        "            if l.strip() == '-1.0':  # Checking if line contains '-1.0'\n",
        "                label = 0  # Setting label to 0\n",
        "            if l.startswith('    '):  # Checking if line starts with four spaces\n",
        "                feature = l.split()  # Splitting the line into components\n",
        "                node = feature[3]  # Extracting the node information\n",
        "                nodes.append(node)  # Appending node to the list\n",
        "            elif l.startswith(' '):  # Checking if line starts with a single space\n",
        "                lnk = l.split()  # Splitting the line into components\n",
        "                # edge: (from, to,) (1-based index)\n",
        "                if int(lnk[0]) - 1 < len(nodes):  # Checking if the starting node index is within bounds\n",
        "                    links.append((  # Appending a tuple representing an edge to the list\n",
        "                        int(lnk[0])-1,  # Starting node index (zero-based)\n",
        "                        int(lnk[1])-1,  # Ending node index (zero-based)\n",
        "                        # int(lnk[2]) ignore edge weight\n",
        "                    ))\n",
        "        return nodes, np.array(links), label  # Returning nodes, links, and label\n",
        "\n",
        "    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]  # Returning parsed samples with progress bar display if the sample length is greater than 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cce26cbbdb6240aabaa42282a7e8e2cf",
            "6c3a23e272a54e6b9dc151fe4c90104d",
            "43eb2c06808b4140a6739f6d24b491e7",
            "991bd379c4a845e9ac9b07a0507a1649",
            "5b6809cfe33746d79be3f1d15a6fee3f",
            "f6eccc4017d44dcbb6f11379306f4a56",
            "91247565deb34520ac596409c767e8a2",
            "0ae024101eee4e0f9dadc2f2ecebdc80",
            "35a13bbd38544d9ba002ec121cd7b184",
            "bbdf7f791bdf4ece9581dab337a62f59",
            "f5493d76ba6441a5a8e34e2b125f1491"
          ]
        },
        "id": "JyWizsR-Bu5S",
        "outputId": "6684ea8c-a1d8-4a24-9847-a5ce58911c6d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cce26cbbdb6240aabaa42282a7e8e2cf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training_set = read_sdf('train.sdf')\n",
        "training_set, validation_set = train_test_split(training_set, test_size=0.15,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6f1d2ddcec4b42008d5d8278e1c84c6e",
            "b2ae8b06027240d7bad1e96141d9dbc0",
            "9ca5e9283796432887c5dfae34afed74",
            "d1280f6b72724e9e83303aa62a9ac911",
            "79d2a390548a43668ce7b88600321560",
            "462ef6b3d6804c7c837e4a80b6c5f6b7",
            "33102b80c8084ca88c7fb8e061873fc2",
            "06b192ae3d5e4f1b8cb9aa6f33d706f1",
            "049d85a6e5e344d5a4fea0e087aabfb3",
            "dba62aab1f9b4e9db48da79c446a0a42",
            "29ff699d9cd24ef8bfe4d65eb3255557"
          ]
        },
        "id": "pugbnsOxBu5V",
        "outputId": "108b39d8-dc90-4315-f9f1-b97dd3e39f1c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12326 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f1d2ddcec4b42008d5d8278e1c84c6e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "testing_set  = read_sdf('test_x.sdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0kBmf9cBu5X",
        "outputId": "1b09781e-4d78-4918-a848-fa69cafd13ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['S', 'S', 'S', 'O', 'O', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0, 13],\n",
            "       [ 0, 19],\n",
            "       [ 1, 15],\n",
            "       [ 1, 20],\n",
            "       [ 2,  6],\n",
            "       [ 2,  7],\n",
            "       [ 2,  8],\n",
            "       [ 2, 25],\n",
            "       [ 3, 16],\n",
            "       [ 4, 22],\n",
            "       [ 5, 22],\n",
            "       [ 9, 13],\n",
            "       [ 9, 15],\n",
            "       [ 9, 16],\n",
            "       [10, 11],\n",
            "       [10, 13],\n",
            "       [10, 18],\n",
            "       [11, 17],\n",
            "       [12, 15],\n",
            "       [12, 21],\n",
            "       [13, 14],\n",
            "       [14, 17],\n",
            "       [16, 19],\n",
            "       [17, 22],\n",
            "       [18, 23],\n",
            "       [18, 24],\n",
            "       [20, 21],\n",
            "       [20, 28],\n",
            "       [21, 29],\n",
            "       [23, 26],\n",
            "       [24, 27],\n",
            "       [25, 26],\n",
            "       [25, 27],\n",
            "       [28, 30],\n",
            "       [29, 31],\n",
            "       [30, 31]]), 0)\n"
          ]
        }
      ],
      "source": [
        "print(training_set[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcVNsJjyBu5Y"
      },
      "source": [
        "## Visualizing/Inspecting a Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBTiUhvFBu5Z"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet networkx\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "colors = cm.rainbow(np.linspace(0, 1, 50))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. The function `visualize` takes a `sample` as input. The sample is assumed to be a tuple containing information about nodes and edges.\n",
        "\n",
        "2. Within the function:\n",
        "   - It initializes an empty graph `G` using NetworkX.\n",
        "   - It extracts nodes and edges information from the `sample`.\n",
        "   - It initializes a dictionary `labeldict` to store labels for nodes and a list `node_color` to store colors for each node.\n",
        "   - It iterates over each node in the `nodes` list, adding nodes to the graph `G`, assigning labels from the `nodes` list to nodes in the graph, and assigning colors based on a hashing scheme.\n",
        "   - It iterates over each edge in the `edges` list, adding edges to the graph `G`.\n",
        "   - It draws the graph `G` using NetworkX's `draw` function, with node labels, node colors, and displays it using `plt.show()` (assuming `matplotlib.pyplot` is imported elsewhere).\n",
        "   - It returns the graph `G`.\n",
        "\n"
      ],
      "metadata": {
        "id": "i5yFJeKNasWE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdZIrQT2Bu5a"
      },
      "outputs": [],
      "source": [
        "def visualize(sample):  # Defining a function named visualize that takes a sample parameter\n",
        "    G=nx.Graph()  # Creating an empty graph object using NetworkX\n",
        "    nodes = sample[0]  # Extracting nodes from the sample\n",
        "    edges = sample[1]  # Extracting edges from the sample\n",
        "\n",
        "    labeldict={}  # Initializing an empty dictionary to store node labels\n",
        "    node_color=[]  # Initializing an empty list to store node colors\n",
        "\n",
        "    for i,n in enumerate(nodes):  # Iterating over nodes and their indices\n",
        "        G.add_node(i)  # Adding a node to the graph with its index\n",
        "        labeldict[i]=n  # Assigning the node label to the index in the label dictionary\n",
        "        node_color.append(colors[hash(n)%len(colors)])  # Assigning a color to the node based on its hash value\n",
        "\n",
        "    # a list of nodes:\n",
        "    for e in edges:  # Iterating over edges\n",
        "        G.add_edge(e[0], e[1])  # Adding an edge between two nodes in the graph\n",
        "\n",
        "    nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)  # Drawing the graph with labels and node colors\n",
        "    plt.show()  # Displaying the graph\n",
        "\n",
        "    return G  # Returning the graph object\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "KmiaUkNvBu5c",
        "outputId": "2ddc6993-bc6e-488f-f209-4401aae2c425"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x7f1eff79ac20>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "plt.clf()\n",
        "visualize(training_set[20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCIguK-BBu5d"
      },
      "source": [
        "## Preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D_ewHVVBu5d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_vocab = 500\n",
        "max_len = 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "all_nodes = [s[0] for s in training_set]\n",
        "tokenizer = Tokenizer(num_words=max_vocab)\n",
        "tokenizer.fit_on_texts(all_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. It imports the `pad_sequences` function from the TensorFlow Keras library for preprocessing sequences and the `random` module for randomization.\n",
        "\n",
        "2. It sets the random seed to 0 to ensure reproducibility of random operations.\n",
        "\n",
        "3. The `prepare_single_batch` function takes a list of samples as input and performs the following steps:\n",
        "   - It extracts nodes from the samples.\n",
        "   - It converts text tokens to sequences using a tokenizer (assuming `tokenizer` is defined elsewhere).\n",
        "   - It pads sequences with zeros to ensure uniform length.\n",
        "   - It determines the maximum length of nodes.\n",
        "   - It adjusts edge indices to account for multiple samples.\n",
        "   - It filters out empty edge lists.\n",
        "   - It creates a mapping from nodes to graphs.\n",
        "   - It flattens node and node-to-graph mapping arrays.\n",
        "   - It returns a dictionary containing data for the batch (node data, edge data, and node-to-graph mapping), along with labels for the samples.\n",
        "\n",
        "4. The `gen_batch` function generates batches from a dataset and accepts the following parameters:\n",
        "   - `dataset`: The dataset from which batches are generated.\n",
        "   - `batch_size` (default: 16): The size of each batch.\n",
        "   - `repeat` (default: False): Whether to repeat batches indefinitely.\n",
        "   - `shuffle` (default: True): Whether to shuffle the dataset before generating batches.\n",
        "\n",
        "5. Within the `gen_batch` function:\n",
        "   - It iterates indefinitely.\n",
        "   - It converts the dataset to a list and shuffles it if shuffling is enabled.\n",
        "   - It determines the length of the dataset.\n",
        "   - It iterates over the dataset in batches based on the specified batch size.\n",
        "   - It selects a batch of samples.\n",
        "   - It yields the prepared batch using the `prepare_single_batch` function.\n",
        "   - It breaks out of the loop if repeating batches is disabled.\n",
        "\n"
      ],
      "metadata": {
        "id": "J--gBAh8bQnU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJMycT8OBu5e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # Importing the pad_sequences function from the preprocessing.sequence module in TensorFlow's Keras\n",
        "import random  # Importing the random module\n",
        "random.seed(0)  # Setting the random seed for reproducibility\n",
        "\n",
        "def prepare_single_batch(samples):  # Defining a function named prepare_single_batch that takes a list of samples as input\n",
        "    sample_nodes = [s[0] for s in samples]  # Extracting nodes from the samples\n",
        "    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)  # Converting text tokens to sequences\n",
        "    sample_nodes = pad_sequences(sample_nodes, padding='post')  # Padding sequences to ensure uniform length\n",
        "    max_nodes_len = np.shape(sample_nodes)[1]  # Determining the maximum length of nodes\n",
        "    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)]  # Adjusting edge indices to account for multiple samples\n",
        "    edges = [e for e in edges if len(e) > 0]  # Filtering out empty edge lists\n",
        "    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]  # Creating a mapping from nodes to graphs\n",
        "\n",
        "    all_nodes = np.reshape(sample_nodes, -1)  # Flattening the node array\n",
        "    all_edges = np.concatenate(edges)  # Concatenating edge arrays\n",
        "\n",
        "    node_to_graph = np.reshape(node_to_graph, -1)  # Flattening the node-to-graph mapping\n",
        "    return {  # Returning a dictionary containing data for the batch\n",
        "        'data': all_nodes,  # Node data\n",
        "        'edges': all_edges,  # Edge data\n",
        "        'node2graph': node_to_graph,  # Mapping from nodes to graphs\n",
        "    }, np.array([s[2] for s in samples])  # Returning labels for the samples\n",
        "\n",
        "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):  # Defining a function named gen_batch that generates batches from a dataset\n",
        "    while True:  # Looping indefinitely\n",
        "        dataset = list(dataset)  # Converting the dataset to a list\n",
        "        if shuffle:  # Checking if shuffling is enabled\n",
        "            random.shuffle(dataset)  # Shuffling the dataset\n",
        "        l = len(dataset)  # Getting the length of the dataset\n",
        "        for ndx in range(0, l, batch_size):  # Iterating over the dataset in batches\n",
        "            batch_samples = dataset[ndx:min(ndx + batch_size, l)]  # Selecting a batch of samples\n",
        "            yield prepare_single_batch(batch_samples)  # Yielding the prepared batch\n",
        "        if not repeat:  # Checking if repeating batches is disabled\n",
        "            break  # Exiting the loop if repeat is False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtlwwjxzBu5g",
        "outputId": "4b7a3774-8e1c-4de2-c63b-5b026c3aa2ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n",
            "[2 2 3 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 2 2 2 3 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 5 2 2 3 3 3 3 3 3 3 3 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "edges\n",
            "[[  0   5]\n",
            " [  1   6]\n",
            " [  2  10]\n",
            " [  2  12]\n",
            " [  2  13]\n",
            " [  3  11]\n",
            " [  3  14]\n",
            " [  3  15]\n",
            " [  4   5]\n",
            " [  4   8]\n",
            " [  4  10]\n",
            " [  5   6]\n",
            " [  6   9]\n",
            " [  7   8]\n",
            " [  7   9]\n",
            " [  7  11]\n",
            " [ 31  43]\n",
            " [ 32  37]\n",
            " [ 33  38]\n",
            " [ 34  39]\n",
            " [ 35  37]\n",
            " [ 35  46]\n",
            " [ 35  47]\n",
            " [ 36  39]\n",
            " [ 36  41]\n",
            " [ 36  42]\n",
            " [ 37  38]\n",
            " [ 38  40]\n",
            " [ 39  40]\n",
            " [ 41  44]\n",
            " [ 42  45]\n",
            " [ 43  44]\n",
            " [ 43  45]\n",
            " [ 46  48]\n",
            " [ 47  49]\n",
            " [ 48  50]\n",
            " [ 49  51]\n",
            " [ 50  52]\n",
            " [ 51  53]\n",
            " [ 62  74]\n",
            " [ 63  85]\n",
            " [ 63  91]\n",
            " [ 64  88]\n",
            " [ 64  92]\n",
            " [ 65  68]\n",
            " [ 65  73]\n",
            " [ 65  76]\n",
            " [ 66  69]\n",
            " [ 66  73]\n",
            " [ 66  78]\n",
            " [ 67  71]\n",
            " [ 67  75]\n",
            " [ 67  77]\n",
            " [ 68  69]\n",
            " [ 70  72]\n",
            " [ 70  75]\n",
            " [ 71  72]\n",
            " [ 73  74]\n",
            " [ 74  75]\n",
            " [ 76  79]\n",
            " [ 76  80]\n",
            " [ 77  81]\n",
            " [ 77  82]\n",
            " [ 78  86]\n",
            " [ 78  87]\n",
            " [ 79  83]\n",
            " [ 80  84]\n",
            " [ 81  89]\n",
            " [ 82  90]\n",
            " [ 83  85]\n",
            " [ 84  85]\n",
            " [ 88  89]\n",
            " [ 88  90]\n",
            " [ 93  98]\n",
            " [ 93 100]\n",
            " [ 94  99]\n",
            " [ 94 106]\n",
            " [ 95 100]\n",
            " [ 96 105]\n",
            " [ 97  98]\n",
            " [ 97  99]\n",
            " [ 97 103]\n",
            " [ 98 102]\n",
            " [ 99 101]\n",
            " [100 101]\n",
            " [102 104]\n",
            " [104 105]]\n",
            "node2grah\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
            "label [0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# showing one batch:\n",
        "for train_batch in gen_batch(training_set, batch_size=4):\n",
        "    for k,v in train_batch[0].items():\n",
        "        print(k)\n",
        "        print(v)\n",
        "        pass\n",
        "    print('label', train_batch[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQsSJPWvBu5h"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet tf2_gnn\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "from tf2_gnn.layers.gnn import GNN, GNNInput"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code sets up the model architecture using TensorFlow and Keras for graph-based tasks:\n",
        "\n",
        "It imports necessary modules and functions from TensorFlow and Keras.\n",
        "It defines input placeholders for the model, including placeholders for node features, edge information, and node-to-graph mapping.\n",
        "It uses an Embedding layer to convert input tokens into fixed-size vectors.\n",
        "It determines the number of graphs (samples) in the batch.\n",
        "It creates input for the Graph Neural Network (GNN) layer.\n",
        "It initializes the GNN layer with default hyperparameters and passes input through it to obtain GNN output.\n",
        "It calculates the mean of GNN output across each graph using the segment_mean function.\n",
        "It adds a Dense layer for prediction with a sigmoid activation function.\n",
        "It creates the model with specified inputs and outputs.\n",
        "Finally, it displays the summary of the model architecture."
      ],
      "metadata": {
        "id": "Ip3buvjAb9sj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQyv7Ny7Bu5h",
        "outputId": "dc96ed62-0283-4c82-d922-987b1adf684d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_1/StatefulPartitionedCall:0', description=\"created by layer 'gnn_1'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_1/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_1'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_1/Sigmoid:0', description=\"created by layer 'dense_1'\")\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOp  ()                           0         ['input_6[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 20)                   10000     ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)        [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TF  ()                           0         ['tf.math.reduce_max_1[0][0]']\n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " gnn_1 (GNN)                 (None, 32)                   22464     ['embedding_1[0][0]',         \n",
            "                                                                     'input_5[0][0]',             \n",
            "                                                                     'input_6[0][0]',             \n",
            "                                                                     'tf.__operators__.add_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_1 (TF  (None, 32)                   0         ['gnn_1[0][0]',               \n",
            " OpLambda)                                                           'input_6[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 1)                    33        ['tf.math.segment_mean_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 32497 (126.94 KB)\n",
            "Trainable params: 32497 (126.94 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf  # Importing TensorFlow library\n",
        "from tensorflow.math import segment_mean  # Importing segment_mean function from TensorFlow math module\n",
        "from tensorflow import keras  # Importing Keras module from TensorFlow\n",
        "from tensorflow.keras import Input, Model  # Importing Input and Model classes from Keras\n",
        "from tensorflow.keras.layers import Embedding, Dense  # Importing Embedding and Dense layers from Keras\n",
        "from tensorflow.keras.optimizers import Adam  # Importing Adam optimizer from Keras\n",
        "\n",
        "# Defining input placeholders for the model\n",
        "data = keras.Input(batch_shape=(None,))\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "\n",
        "# Embedding layer to convert input tokens to fixed-size vectors\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# Determining the number of graphs (samples) in the batch\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# Creating input for GNN (Graph Neural Network) layer\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph,\n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# Creating GNN layer with default hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"hidden_dim\"] = 32\n",
        "gnn_layer = GNN(params)\n",
        "\n",
        "# Passing input through GNN layer to get GNN output\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "# Calculating mean of GNN output across each graph\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# Dense layer for prediction with sigmoid activation\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "# Creating the model with inputs and outputs\n",
        "model = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "# Displaying model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSCNu2PTBu5i"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trial 1"
      ],
      "metadata": {
        "id": "ReWAxo50cQ-2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fjrWKPFBu5j",
        "outputId": "d1cc3779-d6be-4d8d-9bfb-520a977e0c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1330/1330 [==============================] - 22s 14ms/step - loss: 0.2291 - auc: 0.5403 - val_loss: 0.1817 - val_auc: 0.6333\n",
            "Epoch 2/5\n",
            "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1960 - auc: 0.6101 - val_loss: 0.1776 - val_auc: 0.6732\n",
            "Epoch 3/5\n",
            "1330/1330 [==============================] - 19s 14ms/step - loss: 0.1901 - auc: 0.6534 - val_loss: 0.1751 - val_auc: 0.6923\n",
            "Epoch 4/5\n",
            "1330/1330 [==============================] - 22s 16ms/step - loss: 0.1881 - auc: 0.6639 - val_loss: 0.2035 - val_auc: 0.6858\n",
            "Epoch 5/5\n",
            "1330/1330 [==============================] - 19s 14ms/step - loss: 0.1870 - auc: 0.6785 - val_loss: 0.1816 - val_auc: 0.6749\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f1fac32c460>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=5,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KaHbYNPBu5j",
        "outputId": "8b66f25f-c40b-47e3-8d72-b04db1333e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 4s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS4dKttDBu5k",
        "outputId": "39709e80-d6c6-4004-c648-d6ef63280e70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "len(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNim4qVNBu5k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "submission = pd.DataFrame({'label':y_pred})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the function defines input placeholders for the model, including placeholders for node features, edge information, and node-to-graph mapping.\n",
        "It uses an Embedding layer to convert input tokens into fixed-size vectors.\n",
        "It determines the number of graphs (samples) in the batch.\n",
        "It creates input for the Graph Neural Network (GNN) layer.\n",
        "It sets hyperparameters for the GNN layer based on the provided parameters dictionary.\n",
        "It creates the GNN layer with custom hyperparameters.\n",
        "It passes input through the GNN layer to obtain GNN output.\n",
        "It calculates the mean of the GNN output across each graph.\n",
        "It adds a Dense layer for prediction with a sigmoid activation function.\n",
        "It creates the model with specified inputs and outputs.\n",
        "It displays the summary of the model architecture.\n",
        "Finally, it returns the built model."
      ],
      "metadata": {
        "id": "bHc5_oGocc17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(parameters):  # Defining a function named build_model that takes a dictionary of parameters as input\n",
        "\n",
        "    # Defining input placeholders for the model\n",
        "    data = keras.Input(batch_shape=(None,))\n",
        "    edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "    node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "\n",
        "    # Embedding layer to convert input tokens to fixed-size vectors\n",
        "    embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "    # Determining the number of graphs (samples) in the batch\n",
        "    num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "    # Creating input for GNN (Graph Neural Network) layer\n",
        "    gnn_input = GNNInput(\n",
        "        node_features=embeded,\n",
        "        adjacency_lists=(edge,),\n",
        "        node_to_graph_map=node2graph,\n",
        "        num_graphs=num_graph,\n",
        "    )\n",
        "\n",
        "    # Getting default hyperparameters for GNN\n",
        "    params = GNN.get_default_hyperparameters()\n",
        "\n",
        "    # Setting hyperparameters based on the provided parameters dictionary\n",
        "    for key, val in parameters.items():\n",
        "        params[key] = val\n",
        "\n",
        "    # Creating GNN layer with custom hyperparameters\n",
        "    gnn_layer = GNN(params)\n",
        "\n",
        "    # Passing input through GNN layer to get GNN output\n",
        "    gnn_out = gnn_layer(gnn_input)\n",
        "    print('gnn_out', gnn_out)\n",
        "\n",
        "    # Calculating mean of GNN output across each graph\n",
        "    avg = segment_mean(\n",
        "        data=gnn_out,\n",
        "        segment_ids=node2graph\n",
        "    )\n",
        "    print('mean:', avg)\n",
        "\n",
        "    # Dense layer for prediction with sigmoid activation\n",
        "    pred = Dense(1, activation='sigmoid')(avg)\n",
        "    print('pred:', pred)\n",
        "\n",
        "    # Creating the model with inputs and outputs\n",
        "    model = Model(\n",
        "        inputs={\n",
        "            'data': data,\n",
        "            'edges': edge,\n",
        "            'node2grah': node2graph,\n",
        "        },\n",
        "        outputs=pred\n",
        "    )\n",
        "\n",
        "    # Displaying model summary\n",
        "    model.summary()\n",
        "\n",
        "    return model  # Returning the model\n"
      ],
      "metadata": {
        "id": "Q9yMwwG9Gy1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0MeMDaTBu5l"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "def save_output(y_pred, file_name):\n",
        "    submission = pd.DataFrame({'label':y_pred})\n",
        "    submission.index.name = 'id'\n",
        "    submission.to_csv(f'{file_name}.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trial 2:"
      ],
      "metadata": {
        "id": "QiqrUdNoc0j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\"hidden_dim\": 128,\n",
        "              \"message_passing\": \"GGNN\"}\n",
        "\n",
        "model = build_model(parameters)\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=10,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")\n",
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n",
        "# save the test prediction\n",
        "save_output(y_pred, \"sample_submission2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2KtiO5NHUnD",
        "outputId": "a0d5a24e-17d4-4249-ea49-2d072e451b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='gnn_2/StatefulPartitionedCall:0', description=\"created by layer 'gnn_2'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='tf.math.segment_mean_2/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_2'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_2/Sigmoid:0', description=\"created by layer 'dense_2'\")\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)        [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)        [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_2 (TFOp  ()                           0         ['input_9[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)     (None, 20)                   10000     ['input_7[0][0]']             \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)        [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TF  ()                           0         ['tf.math.reduce_max_2[0][0]']\n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " gnn_2 (GNN)                 (None, 128)                  249600    ['embedding_2[0][0]',         \n",
            "                                                                     'input_8[0][0]',             \n",
            "                                                                     'input_9[0][0]',             \n",
            "                                                                     'tf.__operators__.add_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_2 (TF  (None, 128)                  0         ['gnn_2[0][0]',               \n",
            " OpLambda)                                                           'input_9[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1)                    129       ['tf.math.segment_mean_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 259729 (1014.57 KB)\n",
            "Trainable params: 259729 (1014.57 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "1330/1330 [==============================] - 64s 46ms/step - loss: 0.2197 - auc: 0.5582 - val_loss: 0.1987 - val_auc: 0.6189\n",
            "Epoch 2/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1974 - auc: 0.6342 - val_loss: 0.1811 - val_auc: 0.6571\n",
            "Epoch 3/10\n",
            "1330/1330 [==============================] - 62s 46ms/step - loss: 0.1929 - auc: 0.6689 - val_loss: 0.1729 - val_auc: 0.6883\n",
            "Epoch 4/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1887 - auc: 0.6827 - val_loss: 0.1827 - val_auc: 0.6765\n",
            "Epoch 5/10\n",
            "1330/1330 [==============================] - 62s 46ms/step - loss: 0.1858 - auc: 0.6903 - val_loss: 0.1748 - val_auc: 0.6899\n",
            "Epoch 6/10\n",
            "1330/1330 [==============================] - 62s 46ms/step - loss: 0.1830 - auc: 0.7135 - val_loss: 0.1790 - val_auc: 0.7135\n",
            "Epoch 7/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1815 - auc: 0.7162 - val_loss: 0.1825 - val_auc: 0.6619\n",
            "Epoch 8/10\n",
            "1330/1330 [==============================] - 59s 44ms/step - loss: 0.1840 - auc: 0.7076 - val_loss: 0.1670 - val_auc: 0.7208\n",
            "Epoch 9/10\n",
            "1330/1330 [==============================] - 58s 44ms/step - loss: 0.1789 - auc: 0.7295 - val_loss: 0.1718 - val_auc: 0.7245\n",
            "Epoch 10/10\n",
            "1330/1330 [==============================] - 62s 46ms/step - loss: 0.1801 - auc: 0.7240 - val_loss: 0.1931 - val_auc: 0.6781\n",
            "771/771 [==============================] - 12s 15ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trial 3:"
      ],
      "metadata": {
        "id": "YKPrUgm8c73j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\"hidden_dim\": 128,\n",
        "              \"message_passing\": \"RGCN\"}\n",
        "\n",
        "model = build_model(parameters)\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=10,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")\n",
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n",
        "# save the test prediction\n",
        "save_output(y_pred, \"sample_submission3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1V76E9kHlc4",
        "outputId": "2ac41cef-666c-4ade-cb20-4d5a5b82d617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='gnn_3/StatefulPartitionedCall:0', description=\"created by layer 'gnn_3'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='tf.math.segment_mean_3/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_3'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_3/Sigmoid:0', description=\"created by layer 'dense_3'\")\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOp  ()                           0         ['input_12[0][0]']            \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (None, 20)                   10000     ['input_10[0][0]']            \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)       [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TF  ()                           0         ['tf.math.reduce_max_3[0][0]']\n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " gnn_3 (GNN)                 (None, 128)                  249600    ['embedding_3[0][0]',         \n",
            "                                                                     'input_11[0][0]',            \n",
            "                                                                     'input_12[0][0]',            \n",
            "                                                                     'tf.__operators__.add_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_3 (TF  (None, 128)                  0         ['gnn_3[0][0]',               \n",
            " OpLambda)                                                           'input_12[0][0]']            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 1)                    129       ['tf.math.segment_mean_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 259729 (1014.57 KB)\n",
            "Trainable params: 259729 (1014.57 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "1330/1330 [==============================] - 64s 46ms/step - loss: 0.2206 - auc: 0.5581 - val_loss: 0.2203 - val_auc: 0.5678\n",
            "Epoch 2/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1978 - auc: 0.6373 - val_loss: 0.1826 - val_auc: 0.6803\n",
            "Epoch 3/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1947 - auc: 0.6509 - val_loss: 0.1841 - val_auc: 0.6405\n",
            "Epoch 4/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1896 - auc: 0.6768 - val_loss: 0.1994 - val_auc: 0.6415\n",
            "Epoch 5/10\n",
            "1330/1330 [==============================] - 61s 46ms/step - loss: 0.1869 - auc: 0.6868 - val_loss: 0.1719 - val_auc: 0.6959\n",
            "Epoch 6/10\n",
            "1330/1330 [==============================] - 61s 46ms/step - loss: 0.1852 - auc: 0.6998 - val_loss: 0.1749 - val_auc: 0.6917\n",
            "Epoch 7/10\n",
            "1330/1330 [==============================] - 61s 46ms/step - loss: 0.1843 - auc: 0.7010 - val_loss: 0.1822 - val_auc: 0.7298\n",
            "Epoch 8/10\n",
            "1330/1330 [==============================] - 57s 43ms/step - loss: 0.1831 - auc: 0.7084 - val_loss: 0.1678 - val_auc: 0.7374\n",
            "Epoch 9/10\n",
            "1330/1330 [==============================] - 61s 46ms/step - loss: 0.1821 - auc: 0.7109 - val_loss: 0.1947 - val_auc: 0.6983\n",
            "Epoch 10/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1791 - auc: 0.7262 - val_loss: 0.1682 - val_auc: 0.7417\n",
            "771/771 [==============================] - 13s 17ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trial 4:"
      ],
      "metadata": {
        "id": "MMrOBs_Ic-b7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\"hidden_dim\": 128,\n",
        "              \"message_passing\": \"RGIN\"}\n",
        "\n",
        "model = build_model(parameters)\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "import math\n",
        "\n",
        "batch_size = 50\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=10,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")\n",
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n",
        "# save the test prediction\n",
        "save_output(y_pred, \"sample_submission4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROepzH0nHmS-",
        "outputId": "e59a9648-ab64-4cda-d7b0-4c0076c38165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='gnn_5/StatefulPartitionedCall:0', description=\"created by layer 'gnn_5'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='tf.math.segment_mean_5/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_5'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_5/Sigmoid:0', description=\"created by layer 'dense_5'\")\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_18 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " input_16 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_5 (TFOp  ()                           0         ['input_18[0][0]']            \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)     (None, 20)                   10000     ['input_16[0][0]']            \n",
            "                                                                                                  \n",
            " input_17 (InputLayer)       [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TF  ()                           0         ['tf.math.reduce_max_5[0][0]']\n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " gnn_5 (GNN)                 (None, 128)                  249600    ['embedding_5[0][0]',         \n",
            "                                                                     'input_17[0][0]',            \n",
            "                                                                     'input_18[0][0]',            \n",
            "                                                                     'tf.__operators__.add_5[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_5 (TF  (None, 128)                  0         ['gnn_5[0][0]',               \n",
            " OpLambda)                                                           'input_18[0][0]']            \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 1)                    129       ['tf.math.segment_mean_5[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 259729 (1014.57 KB)\n",
            "Trainable params: 259729 (1014.57 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "426/426 [==============================] - 64s 145ms/step - loss: 0.2532 - auc: 0.5049 - val_loss: 0.1729 - val_auc: 0.6537\n",
            "Epoch 2/10\n",
            "426/426 [==============================] - 58s 136ms/step - loss: 0.2017 - auc: 0.5983 - val_loss: 0.2073 - val_auc: 0.6592\n",
            "Epoch 3/10\n",
            "426/426 [==============================] - 60s 141ms/step - loss: 0.1927 - auc: 0.6520 - val_loss: 0.1753 - val_auc: 0.6619\n",
            "Epoch 4/10\n",
            "426/426 [==============================] - 60s 141ms/step - loss: 0.1890 - auc: 0.6706 - val_loss: 0.1915 - val_auc: 0.6823\n",
            "Epoch 5/10\n",
            "426/426 [==============================] - 62s 145ms/step - loss: 0.1871 - auc: 0.6720 - val_loss: 0.1887 - val_auc: 0.6780\n",
            "Epoch 6/10\n",
            "426/426 [==============================] - 61s 143ms/step - loss: 0.1860 - auc: 0.6838 - val_loss: 0.1677 - val_auc: 0.7430\n",
            "Epoch 7/10\n",
            "426/426 [==============================] - 59s 139ms/step - loss: 0.1847 - auc: 0.6875 - val_loss: 0.1915 - val_auc: 0.6729\n",
            "Epoch 8/10\n",
            "426/426 [==============================] - 60s 141ms/step - loss: 0.1833 - auc: 0.6916 - val_loss: 0.1759 - val_auc: 0.7434\n",
            "Epoch 9/10\n",
            "426/426 [==============================] - 62s 145ms/step - loss: 0.1824 - auc: 0.6947 - val_loss: 0.2008 - val_auc: 0.7256\n",
            "Epoch 10/10\n",
            "426/426 [==============================] - 59s 139ms/step - loss: 0.1821 - auc: 0.7013 - val_loss: 0.1862 - val_auc: 0.7364\n",
            "771/771 [==============================] - 12s 15ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trial 5:"
      ],
      "metadata": {
        "id": "zlQKc307dBUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\"hidden_dim\": 128,\n",
        "              \"message_passing\": \"RGIN\"}\n",
        "\n",
        "model = build_model(parameters)\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "\n",
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=10,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")\n",
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n",
        "# save the test prediction\n",
        "save_output(y_pred, \"sample_submission5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zFNX0q9THnEn",
        "outputId": "640c5639-8ae8-4294-c0d6-911e0980069f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='gnn_6/StatefulPartitionedCall:0', description=\"created by layer 'gnn_6'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='tf.math.segment_mean_6/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_6'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_6/Sigmoid:0', description=\"created by layer 'dense_6'\")\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_21 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " input_19 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_6 (TFOp  ()                           0         ['input_21[0][0]']            \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " embedding_6 (Embedding)     (None, 20)                   10000     ['input_19[0][0]']            \n",
            "                                                                                                  \n",
            " input_20 (InputLayer)       [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TF  ()                           0         ['tf.math.reduce_max_6[0][0]']\n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " gnn_6 (GNN)                 (None, 128)                  249600    ['embedding_6[0][0]',         \n",
            "                                                                     'input_20[0][0]',            \n",
            "                                                                     'input_21[0][0]',            \n",
            "                                                                     'tf.__operators__.add_6[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_6 (TF  (None, 128)                  0         ['gnn_6[0][0]',               \n",
            " OpLambda)                                                           'input_21[0][0]']            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 1)                    129       ['tf.math.segment_mean_6[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 259729 (1014.57 KB)\n",
            "Trainable params: 259729 (1014.57 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "1330/1330 [==============================] - 64s 45ms/step - loss: 0.2195 - auc: 0.5635 - val_loss: 0.1969 - val_auc: 0.6652\n",
            "Epoch 2/10\n",
            "1330/1330 [==============================] - 64s 48ms/step - loss: 0.1955 - auc: 0.6502 - val_loss: 0.1791 - val_auc: 0.7079\n",
            "Epoch 3/10\n",
            "1330/1330 [==============================] - 62s 47ms/step - loss: 0.1895 - auc: 0.6885 - val_loss: 0.1743 - val_auc: 0.7063\n",
            "Epoch 4/10\n",
            "1330/1330 [==============================] - 59s 44ms/step - loss: 0.1860 - auc: 0.7020 - val_loss: 0.1862 - val_auc: 0.7205\n",
            "Epoch 5/10\n",
            "1330/1330 [==============================] - 61s 46ms/step - loss: 0.1841 - auc: 0.7091 - val_loss: 0.1708 - val_auc: 0.7129\n",
            "Epoch 6/10\n",
            "1330/1330 [==============================] - 61s 46ms/step - loss: 0.1815 - auc: 0.7163 - val_loss: 0.1670 - val_auc: 0.7365\n",
            "Epoch 7/10\n",
            "1330/1330 [==============================] - 61s 46ms/step - loss: 0.1827 - auc: 0.7102 - val_loss: 0.1704 - val_auc: 0.7415\n",
            "Epoch 8/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1792 - auc: 0.7309 - val_loss: 0.1685 - val_auc: 0.7150\n",
            "Epoch 9/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1799 - auc: 0.7238 - val_loss: 0.1704 - val_auc: 0.7119\n",
            "Epoch 10/10\n",
            "1330/1330 [==============================] - 62s 46ms/step - loss: 0.1796 - auc: 0.7303 - val_loss: 0.1762 - val_auc: 0.7443\n",
            "771/771 [==============================] - 12s 15ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trial 6:"
      ],
      "metadata": {
        "id": "Vj-QilaKdFUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\"hidden_dim\": 128,\n",
        "              \"message_passing\": \"GNN-Egde-MLP\"}\n",
        "\n",
        "model = build_model(parameters)\n",
        "\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=10,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")\n",
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n",
        "# save the test prediction\n",
        "save_output(y_pred, \"sample_submission6\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu-c9Wb9Hn1I",
        "outputId": "7560dd80-480e-4449-cd37-373dcc14c154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='gnn_7/StatefulPartitionedCall:0', description=\"created by layer 'gnn_7'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='tf.math.segment_mean_7/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_7'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_7/Sigmoid:0', description=\"created by layer 'dense_7'\")\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_24 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " input_22 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_7 (TFOp  ()                           0         ['input_24[0][0]']            \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)     (None, 20)                   10000     ['input_22[0][0]']            \n",
            "                                                                                                  \n",
            " input_23 (InputLayer)       [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TF  ()                           0         ['tf.math.reduce_max_7[0][0]']\n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " gnn_7 (GNN)                 (None, 128)                  249600    ['embedding_7[0][0]',         \n",
            "                                                                     'input_23[0][0]',            \n",
            "                                                                     'input_24[0][0]',            \n",
            "                                                                     'tf.__operators__.add_7[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_7 (TF  (None, 128)                  0         ['gnn_7[0][0]',               \n",
            " OpLambda)                                                           'input_24[0][0]']            \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 1)                    129       ['tf.math.segment_mean_7[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 259729 (1014.57 KB)\n",
            "Trainable params: 259729 (1014.57 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "1330/1330 [==============================] - 62s 45ms/step - loss: 0.2237 - auc: 0.5337 - val_loss: 0.2140 - val_auc: 0.5949\n",
            "Epoch 2/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1980 - auc: 0.6317 - val_loss: 0.1781 - val_auc: 0.6592\n",
            "Epoch 3/10\n",
            "1330/1330 [==============================] - 59s 44ms/step - loss: 0.1913 - auc: 0.6606 - val_loss: 0.1806 - val_auc: 0.6877\n",
            "Epoch 4/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1893 - auc: 0.6792 - val_loss: 0.1789 - val_auc: 0.7017\n",
            "Epoch 5/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1846 - auc: 0.7017 - val_loss: 0.1660 - val_auc: 0.7223\n",
            "Epoch 6/10\n",
            "1330/1330 [==============================] - 64s 48ms/step - loss: 0.1827 - auc: 0.7124 - val_loss: 0.1739 - val_auc: 0.7190\n",
            "Epoch 7/10\n",
            "1330/1330 [==============================] - 62s 47ms/step - loss: 0.1803 - auc: 0.7240 - val_loss: 0.1813 - val_auc: 0.6805\n",
            "Epoch 8/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1802 - auc: 0.7220 - val_loss: 0.1818 - val_auc: 0.7134\n",
            "Epoch 9/10\n",
            "1330/1330 [==============================] - 57s 43ms/step - loss: 0.1826 - auc: 0.7116 - val_loss: 0.1632 - val_auc: 0.7014\n",
            "Epoch 10/10\n",
            "1330/1330 [==============================] - 61s 46ms/step - loss: 0.1803 - auc: 0.7307 - val_loss: 0.1826 - val_auc: 0.6933\n",
            "771/771 [==============================] - 12s 15ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trial 7:"
      ],
      "metadata": {
        "id": "FnHDGBjDdI90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\"hidden_dim\": 128,\n",
        "              \"message_passing\": \"GNN-FiLM\"}\n",
        "\n",
        "model = build_model(parameters)\n",
        "\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=10,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")\n",
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n",
        "# save the test prediction\n",
        "save_output(y_pred, \"sample_submission7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9r_DpM5Ho3O",
        "outputId": "db5c9ad2-781b-418f-d81e-577bd5cdc908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='gnn_8/StatefulPartitionedCall:0', description=\"created by layer 'gnn_8'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='tf.math.segment_mean_8/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_8'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_8/Sigmoid:0', description=\"created by layer 'dense_8'\")\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_27 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " input_25 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_8 (TFOp  ()                           0         ['input_27[0][0]']            \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " embedding_8 (Embedding)     (None, 20)                   10000     ['input_25[0][0]']            \n",
            "                                                                                                  \n",
            " input_26 (InputLayer)       [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_8 (TF  ()                           0         ['tf.math.reduce_max_8[0][0]']\n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " gnn_8 (GNN)                 (None, 128)                  249600    ['embedding_8[0][0]',         \n",
            "                                                                     'input_26[0][0]',            \n",
            "                                                                     'input_27[0][0]',            \n",
            "                                                                     'tf.__operators__.add_8[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_8 (TF  (None, 128)                  0         ['gnn_8[0][0]',               \n",
            " OpLambda)                                                           'input_27[0][0]']            \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 1)                    129       ['tf.math.segment_mean_8[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 259729 (1014.57 KB)\n",
            "Trainable params: 259729 (1014.57 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "1330/1330 [==============================] - 63s 45ms/step - loss: 0.2222 - auc: 0.5510 - val_loss: 0.1797 - val_auc: 0.6671\n",
            "Epoch 2/10\n",
            "1330/1330 [==============================] - 57s 43ms/step - loss: 0.1956 - auc: 0.6500 - val_loss: 0.1779 - val_auc: 0.6622\n",
            "Epoch 3/10\n",
            "1330/1330 [==============================] - 59s 45ms/step - loss: 0.1912 - auc: 0.6634 - val_loss: 0.1858 - val_auc: 0.6666\n",
            "Epoch 4/10\n",
            "1330/1330 [==============================] - 62s 47ms/step - loss: 0.1877 - auc: 0.6807 - val_loss: 0.1853 - val_auc: 0.6751\n",
            "Epoch 5/10\n",
            "1330/1330 [==============================] - 59s 45ms/step - loss: 0.1864 - auc: 0.6915 - val_loss: 0.1700 - val_auc: 0.7079\n",
            "Epoch 6/10\n",
            "1330/1330 [==============================] - 59s 45ms/step - loss: 0.1831 - auc: 0.7111 - val_loss: 0.1800 - val_auc: 0.7129\n",
            "Epoch 7/10\n",
            "1330/1330 [==============================] - 58s 44ms/step - loss: 0.1805 - auc: 0.7326 - val_loss: 0.1794 - val_auc: 0.6843\n",
            "Epoch 8/10\n",
            "1330/1330 [==============================] - 59s 44ms/step - loss: 0.1830 - auc: 0.7258 - val_loss: 0.1857 - val_auc: 0.6827\n",
            "Epoch 9/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1834 - auc: 0.7169 - val_loss: 0.1965 - val_auc: 0.6754\n",
            "Epoch 10/10\n",
            "1330/1330 [==============================] - 60s 45ms/step - loss: 0.1820 - auc: 0.7266 - val_loss: 0.1686 - val_auc: 0.7262\n",
            "771/771 [==============================] - 12s 15ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trial 8:"
      ],
      "metadata": {
        "id": "8rL3ltrUdOAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "parameters = {\"hidden_dim\": 128,\n",
        "              \"message_passing\": \"GNN-FiLM\",\n",
        "              \"num_layers\": 10}\n",
        "\n",
        "model = build_model(parameters)\n",
        "\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "import math\n",
        "\n",
        "batch_size = 50\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=10,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")\n",
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n",
        "# save the test prediction\n",
        "save_output(y_pred, \"sample_submission8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUwrcl-eHply",
        "outputId": "4b92e169-1bbd-4ab1-ccb7-613733165759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='gnn_10/StatefulPartitionedCall:0', description=\"created by layer 'gnn_10'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='tf.math.segment_mean_10/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_10'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_10/Sigmoid:0', description=\"created by layer 'dense_10'\")\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_33 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " input_31 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_10 (TFO  ()                           0         ['input_33[0][0]']            \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " embedding_10 (Embedding)    (None, 20)                   10000     ['input_31[0][0]']            \n",
            "                                                                                                  \n",
            " input_32 (InputLayer)       [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_10 (T  ()                           0         ['tf.math.reduce_max_10[0][0]'\n",
            " FOpLambda)                                                         ]                             \n",
            "                                                                                                  \n",
            " gnn_10 (GNN)                (None, 128)                  843264    ['embedding_10[0][0]',        \n",
            "                                                                     'input_32[0][0]',            \n",
            "                                                                     'input_33[0][0]',            \n",
            "                                                                     'tf.__operators__.add_10[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_10 (T  (None, 128)                  0         ['gnn_10[0][0]',              \n",
            " FOpLambda)                                                          'input_33[0][0]']            \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 1)                    129       ['tf.math.segment_mean_10[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 853393 (3.26 MB)\n",
            "Trainable params: 853393 (3.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "426/426 [==============================] - 213s 482ms/step - loss: 0.2522 - auc: 0.4910 - val_loss: 0.2012 - val_auc: 0.6095\n",
            "Epoch 2/10\n",
            "426/426 [==============================] - 201s 472ms/step - loss: 0.2078 - auc: 0.5408 - val_loss: 0.2207 - val_auc: 0.6358\n",
            "Epoch 3/10\n",
            "426/426 [==============================] - 201s 471ms/step - loss: 0.2023 - auc: 0.5743 - val_loss: 0.1842 - val_auc: 0.6166\n",
            "Epoch 4/10\n",
            "426/426 [==============================] - 202s 473ms/step - loss: 0.2002 - auc: 0.5848 - val_loss: 0.1766 - val_auc: 0.6818\n",
            "Epoch 5/10\n",
            "426/426 [==============================] - 201s 473ms/step - loss: 0.1974 - auc: 0.5925 - val_loss: 0.1988 - val_auc: 0.6032\n",
            "Epoch 6/10\n",
            "426/426 [==============================] - 200s 470ms/step - loss: 0.1957 - auc: 0.6041 - val_loss: 0.1749 - val_auc: 0.6005\n",
            "Epoch 7/10\n",
            "426/426 [==============================] - 203s 475ms/step - loss: 0.1959 - auc: 0.5994 - val_loss: 0.2030 - val_auc: 0.6939\n",
            "Epoch 8/10\n",
            "426/426 [==============================] - 206s 483ms/step - loss: 0.1936 - auc: 0.6216 - val_loss: 0.1587 - val_auc: 0.6777\n",
            "Epoch 9/10\n",
            "426/426 [==============================] - 206s 485ms/step - loss: 0.1927 - auc: 0.6282 - val_loss: 0.1826 - val_auc: 0.6908\n",
            "Epoch 10/10\n",
            "426/426 [==============================] - 203s 476ms/step - loss: 0.1917 - auc: 0.6413 - val_loss: 0.1723 - val_auc: 0.6601\n",
            "771/771 [==============================] - 34s 44ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trial 9:"
      ],
      "metadata": {
        "id": "P1C5RsjjdRi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\"hidden_dim\": 128,\n",
        "              \"message_passing\": \"GNN-Egde-MLP\",\n",
        "              \"layer_input_dropout_rate\": 0.5}\n",
        "\n",
        "model = build_model(parameters)\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "\n",
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=10,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")\n",
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n",
        "# save the test prediction\n",
        "save_output(y_pred, \"sample_submission9\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMQCJn7eHqRT",
        "outputId": "eb997195-eb17-4cf4-cd70-5f0837d5549c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='gnn_12/StatefulPartitionedCall:0', description=\"created by layer 'gnn_12'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='tf.math.segment_mean_12/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_12'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_12/Sigmoid:0', description=\"created by layer 'dense_12'\")\n",
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_39 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " input_37 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_12 (TFO  ()                           0         ['input_39[0][0]']            \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " embedding_12 (Embedding)    (None, 20)                   10000     ['input_37[0][0]']            \n",
            "                                                                                                  \n",
            " input_38 (InputLayer)       [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_12 (T  ()                           0         ['tf.math.reduce_max_12[0][0]'\n",
            " FOpLambda)                                                         ]                             \n",
            "                                                                                                  \n",
            " gnn_12 (GNN)                (None, 128)                  249600    ['embedding_12[0][0]',        \n",
            "                                                                     'input_38[0][0]',            \n",
            "                                                                     'input_39[0][0]',            \n",
            "                                                                     'tf.__operators__.add_12[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_12 (T  (None, 128)                  0         ['gnn_12[0][0]',              \n",
            " FOpLambda)                                                          'input_39[0][0]']            \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 1)                    129       ['tf.math.segment_mean_12[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 259729 (1014.57 KB)\n",
            "Trainable params: 259729 (1014.57 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "1330/1330 [==============================] - 71s 51ms/step - loss: 0.2237 - auc: 0.5363 - val_loss: 0.2068 - val_auc: 0.5752\n",
            "Epoch 2/10\n",
            "1330/1330 [==============================] - 66s 50ms/step - loss: 0.1974 - auc: 0.6389 - val_loss: 0.2069 - val_auc: 0.6943\n",
            "Epoch 3/10\n",
            "1330/1330 [==============================] - 72s 54ms/step - loss: 0.1944 - auc: 0.6518 - val_loss: 0.1844 - val_auc: 0.7103\n",
            "Epoch 4/10\n",
            "1330/1330 [==============================] - 75s 56ms/step - loss: 0.1908 - auc: 0.6690 - val_loss: 0.1770 - val_auc: 0.6680\n",
            "Epoch 5/10\n",
            "1330/1330 [==============================] - 79s 59ms/step - loss: 0.1891 - auc: 0.6755 - val_loss: 0.1789 - val_auc: 0.6460\n",
            "Epoch 6/10\n",
            "1330/1330 [==============================] - 78s 59ms/step - loss: 0.1867 - auc: 0.6832 - val_loss: 0.1698 - val_auc: 0.6934\n",
            "Epoch 7/10\n",
            "1330/1330 [==============================] - 66s 50ms/step - loss: 0.1866 - auc: 0.6842 - val_loss: 0.1738 - val_auc: 0.7163\n",
            "Epoch 8/10\n",
            "1330/1330 [==============================] - 66s 49ms/step - loss: 0.1854 - auc: 0.7021 - val_loss: 0.1748 - val_auc: 0.7324\n",
            "Epoch 9/10\n",
            "1330/1330 [==============================] - 69s 52ms/step - loss: 0.1852 - auc: 0.6947 - val_loss: 0.1733 - val_auc: 0.7119\n",
            "Epoch 10/10\n",
            "1330/1330 [==============================] - 66s 50ms/step - loss: 0.1849 - auc: 0.6966 - val_loss: 0.1837 - val_auc: 0.6828\n",
            "771/771 [==============================] - 12s 15ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trial 10:"
      ],
      "metadata": {
        "id": "5aG72IoRdUcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\"hidden_dim\": 128,\n",
        "              \"message_passing\": \"GNN-FiLM\",\n",
        "              \"layer_input_dropout_rate\": 0.5}\n",
        "\n",
        "model = build_model(parameters)\n",
        "\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")\n",
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=10,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")\n",
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n",
        "# save the test prediction\n",
        "save_output(y_pred, \"sample_submission10\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE3vD2FbHrED",
        "outputId": "d4d2a5ba-b34b-4d81-d9a7-911bf526f312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='gnn_15/StatefulPartitionedCall:0', description=\"created by layer 'gnn_15'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='tf.math.segment_mean_15/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_15'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_15/Sigmoid:0', description=\"created by layer 'dense_15'\")\n",
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_48 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " input_46 (InputLayer)       [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_15 (TFO  ()                           0         ['input_48[0][0]']            \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " embedding_15 (Embedding)    (None, 20)                   10000     ['input_46[0][0]']            \n",
            "                                                                                                  \n",
            " input_47 (InputLayer)       [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_15 (T  ()                           0         ['tf.math.reduce_max_15[0][0]'\n",
            " FOpLambda)                                                         ]                             \n",
            "                                                                                                  \n",
            " gnn_15 (GNN)                (None, 128)                  249600    ['embedding_15[0][0]',        \n",
            "                                                                     'input_47[0][0]',            \n",
            "                                                                     'input_48[0][0]',            \n",
            "                                                                     'tf.__operators__.add_15[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_15 (T  (None, 128)                  0         ['gnn_15[0][0]',              \n",
            " FOpLambda)                                                          'input_48[0][0]']            \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 1)                    129       ['tf.math.segment_mean_15[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 259729 (1014.57 KB)\n",
            "Trainable params: 259729 (1014.57 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "1330/1330 [==============================] - 148s 56ms/step - loss: 0.2218 - auc: 0.5500 - val_loss: 0.2097 - val_auc: 0.5207\n",
            "Epoch 2/10\n",
            "1330/1330 [==============================] - 82s 62ms/step - loss: 0.2005 - auc: 0.6240 - val_loss: 0.1855 - val_auc: 0.6588\n",
            "Epoch 3/10\n",
            "1330/1330 [==============================] - 79s 59ms/step - loss: 0.1952 - auc: 0.6487 - val_loss: 0.2251 - val_auc: 0.5576\n",
            "Epoch 4/10\n",
            "1330/1330 [==============================] - 76s 57ms/step - loss: 0.1927 - auc: 0.6554 - val_loss: 0.2357 - val_auc: 0.7239\n",
            "Epoch 5/10\n",
            "1330/1330 [==============================] - 82s 62ms/step - loss: 0.1897 - auc: 0.6825 - val_loss: 0.1813 - val_auc: 0.6523\n",
            "Epoch 6/10\n",
            "1330/1330 [==============================] - 72s 54ms/step - loss: 0.1972 - auc: 0.6451 - val_loss: 0.1874 - val_auc: 0.6482\n",
            "Epoch 7/10\n",
            "1330/1330 [==============================] - 95s 71ms/step - loss: 0.2001 - auc: 0.6227 - val_loss: 0.1988 - val_auc: 0.5686\n",
            "Epoch 8/10\n",
            "1330/1330 [==============================] - 83s 63ms/step - loss: 0.1957 - auc: 0.6355 - val_loss: 0.1882 - val_auc: 0.6544\n",
            "Epoch 9/10\n",
            "1330/1330 [==============================] - 81s 61ms/step - loss: 0.1924 - auc: 0.6561 - val_loss: 0.1877 - val_auc: 0.6617\n",
            "Epoch 10/10\n",
            "1330/1330 [==============================] - 93s 70ms/step - loss: 0.1924 - auc: 0.6564 - val_loss: 0.1835 - val_auc: 0.6127\n",
            "771/771 [==============================] - 16s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# the comparison of the trials:\n",
        "\n",
        "1. **Trial 1:**\n",
        "   - Parameters: `{\"hidden_dim\": 32}`\n",
        "   - Result:\n",
        "     - Loss: 0.1870, AUC: 0.6785\n",
        "     - Validation Loss: 0.1816, Validation AUC: 0.6749\n",
        "  This trial uses a GCNN with a hidden dimension of 32. The model achieves a moderate AUC score on both training and validation sets.\n",
        "\n",
        "2. **Trial 2:**\n",
        "   - Parameters: `{\"hidden_dim\": 128, \"message_passing\": \"GGNN\"}`\n",
        "   - Result:\n",
        "     - Loss: 0.1801, AUC: 0.7240\n",
        "     - Validation Loss: 0.1931, Validation AUC: 0.6781\n",
        "This trial increases the hidden dimension to 128 and employs Gated Graph Neural Network (GGNN) for message passing. The model achieves a higher AUC score compared to Trial 1.\n",
        "\n",
        "3. **Trial 3:**\n",
        "   - Parameters: `{\"hidden_dim\": 128, \"message_passing\": \"RGCN\"}`\n",
        "   - Result:\n",
        "     - Loss: 0.1791, AUC: 0.7262\n",
        "     - Validation Loss: 0.1682, Validation AUC: 0.7417\n",
        "  This trial uses Relational Graph Convolutional Network (RGCN) for message passing. It achieves the highest AUC score on the validation set among the trials.\n",
        "\n",
        "\n",
        "4. **Trial 4:**\n",
        "   - Parameters: `{\"hidden_dim\": 128, \"message_passing\": \"RGIN\"}`\n",
        "   - Batch Size: 50\n",
        "   - Result:\n",
        "     - Loss: 0.1821, AUC: 0.7013\n",
        "     - Validation Loss: 0.1862, Validation AUC: 0.7364\n",
        "This trial employs Relational Graph Isomorphism Network (RGIN) for message passing with a batch size of 50. It achieves a relatively lower AUC score compared to Trial 3.\n",
        "\n",
        "5. **Trial 5:**\n",
        "   - Parameters: `{\"hidden_dim\": 128, \"message_passing\": \"RGIN\"}`\n",
        "   - Batch Size: 16\n",
        "   - Result:\n",
        "     - Loss: 0.1796, AUC: 0.7303\n",
        "     - Validation Loss: 0.1762, Validation AUC: 0.7443\n",
        "Similar to Trial 4 but with a batch size of 16, it achieves a slightly higher AUC score on both training and validation sets.\n",
        "\n",
        "   \n",
        "6. **Trial 6:**\n",
        "   - Parameters: `{\"hidden_dim\": 128, \"message_passing\": \"GNN-Egde-MLP\"}`\n",
        "   - Result:\n",
        "     - Loss: 0.1803, AUC: 0.7307\n",
        "     - Validation Loss: 0.1826, Validation AUC: 0.6933\n",
        "This trial uses a GCNN with GNN-Edge-MLP message passing. It achieves a moderate AUC score on the validation set.\n",
        "\n",
        "7. **Trial 7:**\n",
        "   - Parameters: `{\"hidden_dim\": 128, \"message_passing\": \"GNN-FiLM\"}`\n",
        "   - Result:\n",
        "     - Loss: 0.1820, AUC: 0.7266\n",
        "     - Validation Loss: 0.1686, Validation AUC: 0.7262\n",
        "This trial employs FiLM-based message passing. It achieves a balanced AUC score on both training and validation sets.\n",
        "\n",
        "8. **Trial 8:**\n",
        "   - Parameters: `{\"hidden_dim\": 128, \"message_passing\": \"GNN-FiLM\", \"num_layers\": 10}`\n",
        "   - Result:\n",
        "     - Loss: 0.1917, AUC: 0.6413\n",
        "     - Validation Loss: 0.1723, Validation AUC: 0.6601\n",
        "This trial increases the number of layers to 10 while using FiLM-based message passing. However, it achieves a lower AUC score compared to previous trials.\n",
        "\n",
        "9. **Trial 9:**\n",
        "   - Parameters: `{\"hidden_dim\": 128, \"message_passing\": \"GNN-Egde-MLP\", \"layer_input_dropout_rate\": 0.5}`\n",
        "   - Result:\n",
        "     - Loss: 0.1849, AUC: 0.6966\n",
        "     - Validation Loss: 0.1837, Validation AUC: 0.6828\n",
        "This trial uses GNN-Edge-MLP message passing with layer input dropout rate of 0.5. It achieves a moderate AUC score on the validation set.\n",
        "\n",
        "10. **Trial 10:**\n",
        "    - Parameters: `{\"hidden_dim\": 128, \"message_passing\": \"GNN-FiLM\", \"layer_input_dropout_rate\": 0.5}`\n",
        "    - Result:\n",
        "      - Loss: 0.1924, AUC: 0.6564\n",
        "      - Validation Loss: 0.1835, Validation AUC: 0.6127\n",
        "Similar to Trial 7 but with a layer input dropout rate of 0.5, it achieves a lower AUC score on both training and validation sets.\n",
        "\n",
        "To determine the best trial among the 10, we typically consider the metric that is most important for the specific task at hand, Looking at the validation AUC scores:\n",
        "\n",
        "1. Trial 3 (RGCN message passing) achieved the highest validation AUC of 0.7417.\n",
        "2. Trial 5 (RGIN message passing with batch size 16) achieved a validation AUC of 0.7443.\n",
        "\n",
        "Based on these results, Trial 5 appears to be the best among the 10 trials as it achieved the highest validation AUC score. Therefore, Trial 5 would be considered the best for this task."
      ],
      "metadata": {
        "id": "RIyBMv3tntMg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o47WlqaOKdvm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:root] *",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cce26cbbdb6240aabaa42282a7e8e2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c3a23e272a54e6b9dc151fe4c90104d",
              "IPY_MODEL_43eb2c06808b4140a6739f6d24b491e7",
              "IPY_MODEL_991bd379c4a845e9ac9b07a0507a1649"
            ],
            "layout": "IPY_MODEL_5b6809cfe33746d79be3f1d15a6fee3f"
          }
        },
        "6c3a23e272a54e6b9dc151fe4c90104d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6eccc4017d44dcbb6f11379306f4a56",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_91247565deb34520ac596409c767e8a2",
            "value": "100%"
          }
        },
        "43eb2c06808b4140a6739f6d24b491e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ae024101eee4e0f9dadc2f2ecebdc80",
            "max": 25024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35a13bbd38544d9ba002ec121cd7b184",
            "value": 25024
          }
        },
        "991bd379c4a845e9ac9b07a0507a1649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbdf7f791bdf4ece9581dab337a62f59",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f5493d76ba6441a5a8e34e2b125f1491",
            "value": "‚Äá25024/25024‚Äá[00:03&lt;00:00,‚Äá6631.96it/s]"
          }
        },
        "5b6809cfe33746d79be3f1d15a6fee3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6eccc4017d44dcbb6f11379306f4a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91247565deb34520ac596409c767e8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ae024101eee4e0f9dadc2f2ecebdc80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35a13bbd38544d9ba002ec121cd7b184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbdf7f791bdf4ece9581dab337a62f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5493d76ba6441a5a8e34e2b125f1491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f1d2ddcec4b42008d5d8278e1c84c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2ae8b06027240d7bad1e96141d9dbc0",
              "IPY_MODEL_9ca5e9283796432887c5dfae34afed74",
              "IPY_MODEL_d1280f6b72724e9e83303aa62a9ac911"
            ],
            "layout": "IPY_MODEL_79d2a390548a43668ce7b88600321560"
          }
        },
        "b2ae8b06027240d7bad1e96141d9dbc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_462ef6b3d6804c7c837e4a80b6c5f6b7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_33102b80c8084ca88c7fb8e061873fc2",
            "value": "100%"
          }
        },
        "9ca5e9283796432887c5dfae34afed74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06b192ae3d5e4f1b8cb9aa6f33d706f1",
            "max": 12326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_049d85a6e5e344d5a4fea0e087aabfb3",
            "value": 12326
          }
        },
        "d1280f6b72724e9e83303aa62a9ac911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dba62aab1f9b4e9db48da79c446a0a42",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_29ff699d9cd24ef8bfe4d65eb3255557",
            "value": "‚Äá12326/12326‚Äá[00:01&lt;00:00,‚Äá10415.14it/s]"
          }
        },
        "79d2a390548a43668ce7b88600321560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "462ef6b3d6804c7c837e4a80b6c5f6b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33102b80c8084ca88c7fb8e061873fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06b192ae3d5e4f1b8cb9aa6f33d706f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "049d85a6e5e344d5a4fea0e087aabfb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dba62aab1f9b4e9db48da79c446a0a42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29ff699d9cd24ef8bfe4d65eb3255557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}