{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "üåà A simple linear regression model does not include an activation function and predicts continuous values. In contrast, models like Perceptron and Logistic Regression include activation functions that map the input to a binary output, making them suitable for classification tasks by providing non-linear decision boundaries.\n",
        "\n",
        "üåà A decision tree is a non-parametric supervised learning method used for classification and regression. It splits the data into subsets based on the value of input features, aiming to minimize impurity in the resulting subsets. Logistic regression, on the other hand, is a linear model that predicts the probability of a binary outcome based on input features, using a logistic function to map the linear combination of features to the probability space.\n",
        "\n",
        "üåà Grid search exhaustively searches through a manually specified subset of hyperparameters, evaluating all possible combinations, whereas random search randomly samples hyperparameters from a given distribution for a fixed number of iterations.\n",
        "\n",
        "üåà Bayesian search, such as Bayesian Optimization, uses probabilistic models to select the next hyperparameters to evaluate based on the outcomes of past evaluations, aiming to efficiently explore the hyperparameter space and find optimal values. In contrast, random search does not utilize past evaluations and randomly samples hyperparameters from a given distribution.\n",
        "\n",
        "‚úîÔ∏è Problem Formulation:\n",
        "\n",
        "Define the problem:\n",
        "The problem is to develop a machine learning model for binary classification to predict the outcome of a specific speed dating session based on the profiles of two people. This is part of implementing a recommendation system to better match people in speed dating events. The dataset contains a lot of missing values. The strategy for missing value replacement needs to be tuned. Additionally, the dataset is highly unbalanced, with most samples being unmatched. The goal is to treat the complete workflow from data preprocessing to model training as a single pipeline and search for the hyperparameters for this pipeline.\n",
        "\n",
        "What is the input?\n",
        "The input consists of features describing the profiles of two individuals participating in a speed dating session. These features could include demographic information (age, gender, race), interests, hobbies, personality traits, and other relevant attributes.\n",
        "\n",
        "What is the output?\n",
        "The output is the probability (ranging from 0 to 1 as a float) that the dating session will lead to a successful match. A successful match indicates that both individuals expressed mutual interest in each other after the speed dating session.\n",
        "\n",
        "What data mining function is required?\n",
        "The required data mining function is binary classification. The goal is to predict whether a speed dating session will result in a successful match or not based on the input features. Various classification algorithms can be employed, such as logistic regression, decision trees, random forests, support vector machines, or gradient boosting classifiers.\n",
        "\n",
        "What could be the challenges?\n",
        "Challenges in this task may include:\n",
        "\n",
        "1. Dealing with Missing Values: Developing a strategy to handle missing values in the dataset. Since the dataset contains a lot of missing values, the choice of replacement strategy can significantly impact model performance.\n",
        "\n",
        "2. Addressing Class Imbalance: Since most speed dating sessions may result in unmatched individuals, the dataset is highly unbalanced. Techniques such as oversampling the minority class, undersampling the majority class, or using class-weighted loss functions may be required to address this imbalance.\n",
        "\n",
        "3. Model Selection and Hyperparameter Tuning: Choosing an appropriate classification algorithm and optimizing its hyperparameters to achieve the best performance. Considering the entire pipeline from data preprocessing to model training as a single entity adds complexity to hyperparameter tuning.\n",
        "\n",
        "4. Interpretability: Ensuring that the final model is interpretable, allowing stakeholders to understand the factors influencing the prediction of successful matches.\n",
        "\n",
        "What is the impact?\n",
        "A successful implementation of the recommendation system can significantly enhance the speed dating experience by improving match quality and increasing participant satisfaction. By accurately predicting the probability of successful matches, event organizers can better pair individuals with compatible profiles, leading to more enjoyable and successful speed dating sessions.\n",
        "\n",
        "What is an ideal solution?\n",
        "An ideal solution would be a well-performing classification model that accurately predicts the probability of successful matches in speed dating sessions. The solution should include an end-to-end pipeline encompassing data preprocessing, model selection, and hyperparameter tuning. It should effectively handle missing values, address class imbalance, and produce interpretable results. Regular monitoring and updating of the model based on new data and feedback from speed dating events would ensure continuous improvement and relevance. Ultimately, the solution should enhance the overall speed dating experience for participants by facilitating meaningful connections and interactions."
      ],
      "metadata": {
        "id": "EPzQx6T32Gpq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IWSS0n8B-vR",
        "outputId": "f927aac0-75db-4283-99b1-34b49679e78a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
            "0       0    3       2    14     18         2       2.0     14       12   \n",
            "1       1   14       1     3     10         2       NaN      8        8   \n",
            "2       1   14       1    13     10         8       8.0     10       10   \n",
            "3       1   38       2     9     20        18      13.0      6        7   \n",
            "4       1   24       2    14     20         6       6.0     20       17   \n",
            "\n",
            "     pid  ...  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
            "0  372.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
            "1   63.0  ...      8.0       8.0     7.0     8.0      NaN      NaN       NaN   \n",
            "2  331.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
            "3  200.0  ...      9.0       8.0     8.0     6.0      NaN      NaN       NaN   \n",
            "4  357.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
            "\n",
            "   fun5_3  amb5_3    id  \n",
            "0     NaN     NaN  2583  \n",
            "1     NaN     NaN  6830  \n",
            "2     NaN     NaN  4840  \n",
            "3     NaN     NaN  5508  \n",
            "4     NaN     NaN  4828  \n",
            "\n",
            "[5 rows x 192 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "OjMDMLSqCb-e",
        "outputId": "9a660f77-3acf-4269-eea1-360d15a8e5f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5909 entries, 0 to 5908\n",
            "Columns: 192 entries, gender to id\n",
            "dtypes: float64(173), int64(11), object(8)\n",
            "memory usage: 8.7+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             gender          idg       condtn         wave        round  \\\n",
              "count   5909.000000  5909.000000  5909.000000  5909.000000  5909.000000   \n",
              "unique          NaN          NaN          NaN          NaN          NaN   \n",
              "top             NaN          NaN          NaN          NaN          NaN   \n",
              "freq            NaN          NaN          NaN          NaN          NaN   \n",
              "mean       0.505331    17.360298     1.824843    11.347436    16.850228   \n",
              "std        0.500014    10.947542     0.380133     6.011495     4.389246   \n",
              "min        0.000000     1.000000     1.000000     1.000000     5.000000   \n",
              "25%        0.000000     8.000000     2.000000     7.000000    14.000000   \n",
              "50%        1.000000    16.000000     2.000000    11.000000    18.000000   \n",
              "75%        1.000000    26.000000     2.000000    15.000000    20.000000   \n",
              "max        1.000000    44.000000     2.000000    21.000000    22.000000   \n",
              "\n",
              "           position     positin1       order      partner          pid  ...  \\\n",
              "count   5909.000000  4591.000000  5909.00000  5909.000000  5901.000000  ...   \n",
              "unique          NaN          NaN         NaN          NaN          NaN  ...   \n",
              "top             NaN          NaN         NaN          NaN          NaN  ...   \n",
              "freq            NaN          NaN         NaN          NaN          NaN  ...   \n",
              "mean       9.001523     9.254846     8.91166     8.962938   283.733266  ...   \n",
              "std        5.482368     5.611803     5.45710     5.500706   158.993002  ...   \n",
              "min        1.000000     1.000000     1.00000     1.000000     1.000000  ...   \n",
              "25%        4.000000     4.000000     4.00000     4.000000   153.000000  ...   \n",
              "50%        8.000000     9.000000     8.00000     8.000000   280.000000  ...   \n",
              "75%       13.000000    14.000000    13.00000    13.000000   409.000000  ...   \n",
              "max       22.000000    22.000000    22.00000    22.000000   552.000000  ...   \n",
              "\n",
              "            sinc3_3     intel3_3       fun3_3       amb3_3      attr5_3  \\\n",
              "count   2804.000000  2804.000000  2804.000000  2804.000000  1413.000000   \n",
              "unique          NaN          NaN          NaN          NaN          NaN   \n",
              "top             NaN          NaN          NaN          NaN          NaN   \n",
              "freq            NaN          NaN          NaN          NaN          NaN   \n",
              "mean       8.105563     8.377318     7.644437     7.398716     6.799717   \n",
              "std        1.601011     1.459013     1.757559     1.956924     1.535768   \n",
              "min        2.000000     3.000000     2.000000     1.000000     2.000000   \n",
              "25%        7.000000     8.000000     7.000000     6.000000     6.000000   \n",
              "50%        8.000000     8.000000     8.000000     8.000000     7.000000   \n",
              "75%        9.000000     9.000000     9.000000     9.000000     8.000000   \n",
              "max       12.000000    12.000000    12.000000    12.000000    10.000000   \n",
              "\n",
              "            sinc5_3     intel5_3       fun5_3       amb5_3           id  \n",
              "count   1413.000000  1413.000000  1413.000000  1413.000000  5909.000000  \n",
              "unique          NaN          NaN          NaN          NaN          NaN  \n",
              "top             NaN          NaN          NaN          NaN          NaN  \n",
              "freq            NaN          NaN          NaN          NaN          NaN  \n",
              "mean       7.631989     7.944798     7.162774     7.092711  4191.314943  \n",
              "std        1.498024     1.320919     1.687431     1.713729  2408.009173  \n",
              "min        2.000000     4.000000     1.000000     1.000000     0.000000  \n",
              "25%        7.000000     7.000000     6.000000     6.000000  2124.000000  \n",
              "50%        8.000000     8.000000     7.000000     7.000000  4210.000000  \n",
              "75%        9.000000     9.000000     8.000000     8.000000  6266.000000  \n",
              "max       10.000000    10.000000    10.000000    10.000000  8372.000000  \n",
              "\n",
              "[11 rows x 192 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a86ba2a0-cdab-4392-877e-a9a4c7935403\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>4591.000000</td>\n",
              "      <td>5909.00000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5901.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.505331</td>\n",
              "      <td>17.360298</td>\n",
              "      <td>1.824843</td>\n",
              "      <td>11.347436</td>\n",
              "      <td>16.850228</td>\n",
              "      <td>9.001523</td>\n",
              "      <td>9.254846</td>\n",
              "      <td>8.91166</td>\n",
              "      <td>8.962938</td>\n",
              "      <td>283.733266</td>\n",
              "      <td>...</td>\n",
              "      <td>8.105563</td>\n",
              "      <td>8.377318</td>\n",
              "      <td>7.644437</td>\n",
              "      <td>7.398716</td>\n",
              "      <td>6.799717</td>\n",
              "      <td>7.631989</td>\n",
              "      <td>7.944798</td>\n",
              "      <td>7.162774</td>\n",
              "      <td>7.092711</td>\n",
              "      <td>4191.314943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.500014</td>\n",
              "      <td>10.947542</td>\n",
              "      <td>0.380133</td>\n",
              "      <td>6.011495</td>\n",
              "      <td>4.389246</td>\n",
              "      <td>5.482368</td>\n",
              "      <td>5.611803</td>\n",
              "      <td>5.45710</td>\n",
              "      <td>5.500706</td>\n",
              "      <td>158.993002</td>\n",
              "      <td>...</td>\n",
              "      <td>1.601011</td>\n",
              "      <td>1.459013</td>\n",
              "      <td>1.757559</td>\n",
              "      <td>1.956924</td>\n",
              "      <td>1.535768</td>\n",
              "      <td>1.498024</td>\n",
              "      <td>1.320919</td>\n",
              "      <td>1.687431</td>\n",
              "      <td>1.713729</td>\n",
              "      <td>2408.009173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2124.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>280.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4210.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.00000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>409.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6266.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.00000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>8372.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows √ó 192 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a86ba2a0-cdab-4392-877e-a9a4c7935403')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a86ba2a0-cdab-4392-877e-a9a4c7935403 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a86ba2a0-cdab-4392-877e-a9a4c7935403');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-90b4a717-45df-43b7-8ba5-839822af80fe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-90b4a717-45df-43b7-8ba5-839822af80fe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-90b4a717-45df-43b7-8ba5-839822af80fe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "df.info()\n",
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzQ9tigfChHp",
        "outputId": "73a5e0f6-85db-4f44-9ae2-f64cddabef1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gender      False\n",
            "idg         False\n",
            "condtn      False\n",
            "wave        False\n",
            "round       False\n",
            "            ...  \n",
            "sinc5_3      True\n",
            "intel5_3     True\n",
            "fun5_3       True\n",
            "amb5_3       True\n",
            "id          False\n",
            "Length: 192, dtype: bool\n"
          ]
        }
      ],
      "source": [
        "null_columns = df.isnull().any()\n",
        "print(null_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbzI5sZMCkKW",
        "outputId": "fd3ea639-30c8-4235-dde5-6a85ebad3e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of missing values in each column:\n",
            "gender       0.000000\n",
            "idg          0.000000\n",
            "condtn       0.000000\n",
            "wave         0.000000\n",
            "round        0.000000\n",
            "              ...    \n",
            "sinc5_3     76.087324\n",
            "intel5_3    76.087324\n",
            "fun5_3      76.087324\n",
            "amb5_3      76.087324\n",
            "id           0.000000\n",
            "Length: 192, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Calculate the total number of missing values in each column\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Calculate the total number of values in each column\n",
        "total_values = df.shape[0]\n",
        "\n",
        "# Calculate the percentage of missing values in each column\n",
        "percentage_missing_values = (missing_values / total_values) * 100\n",
        "\n",
        "# Display the result\n",
        "print(\"Percentage of missing values in each column:\")\n",
        "print(percentage_missing_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aozr8jyKClKQ",
        "outputId": "fe5840d3-a3c0-478e-e126-156618b6f149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with 10 percent or more missing values dropped:\n",
            "      gender  idg  condtn  wave  round  position  order  partner    pid  \\\n",
            "0          0    3       2    14     18         2     14       12  372.0   \n",
            "1          1   14       1     3     10         2      8        8   63.0   \n",
            "2          1   14       1    13     10         8     10       10  331.0   \n",
            "3          1   38       2     9     20        18      6        7  200.0   \n",
            "4          1   24       2    14     20         6     20       17  357.0   \n",
            "...      ...  ...     ...   ...    ...       ...    ...      ...    ...   \n",
            "5904       0    1       2     9     20         2     18        1  214.0   \n",
            "5905       1   24       2     9     20        19      5        6  199.0   \n",
            "5906       0   13       2    11     21         5      3       18  290.0   \n",
            "5907       1   10       2     7     16         6      9       10  151.0   \n",
            "5908       0    7       2    21     22         7      2       12  542.0   \n",
            "\n",
            "      match  ...  amb3_1  attr  sinc  intel   fun   amb  like  prob  met    id  \n",
            "0         0  ...    10.0   6.0   5.0    7.0   6.0   6.0   6.0   4.0  0.0  2583  \n",
            "1         0  ...     8.0   5.0   8.0    8.0   5.0   7.0   6.0   6.0  2.0  6830  \n",
            "2         0  ...    10.0   6.0   5.0    7.0   5.0   7.0   6.0   5.0  0.0  4840  \n",
            "3         0  ...     6.0   8.0   8.0    9.0  10.0   9.0   9.0   7.0  2.0  5508  \n",
            "4         0  ...     8.0   8.0   8.0    8.0   7.0   6.0   6.0   5.0  0.0  4828  \n",
            "...     ...  ...     ...   ...   ...    ...   ...   ...   ...   ...  ...   ...  \n",
            "5904      0  ...    10.0   7.0   8.0   10.0   8.0  10.0   7.0   5.0  2.0  3390  \n",
            "5905      0  ...     7.0   5.0   6.0    8.0   5.0   5.0   5.0   5.0  2.0  4130  \n",
            "5906      0  ...     5.0   4.0   7.0    9.0   6.0   7.0   5.0   7.0  0.0  1178  \n",
            "5907      1  ...     8.0   8.0   7.0    7.0   7.0   6.0   9.0   6.0  0.0  5016  \n",
            "5908      0  ...     7.0   5.0   9.0    9.0   4.0   9.0   5.0   5.0  0.0  8149  \n",
            "\n",
            "[5909 rows x 84 columns]\n"
          ]
        }
      ],
      "source": [
        "columns_to_drop = percentage_missing_values[percentage_missing_values >= 10].index\n",
        "\n",
        "# Drop the filtered columns with missing cells >= 10 percent\n",
        "df = df.drop(columns_to_drop, axis=1)\n",
        "\n",
        "# Display the result\n",
        "print(\"Columns with 10 percent or more missing values dropped:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKAgRhSiCouG",
        "outputId": "54deb4bd-8e48-4814-d5b3-d37136fbc9b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "amb_o       512\n",
              "amb         504\n",
              "met_o       275\n",
              "fun_o       265\n",
              "fun         256\n",
              "           ... \n",
              "position      0\n",
              "round         0\n",
              "wave          0\n",
              "condtn        0\n",
              "id            0\n",
              "Length: 84, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df.isnull().sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nktu7uA-Cr-5",
        "outputId": "579bdd01-2fed-442b-8b49-d0eab777815d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of categorical columns: 3\n",
            "Categorical columns:\n",
            "Index(['field', 'from', 'career'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Use the select_dtypes() function to filter columns by data type\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Get the count of categorical columns\n",
        "num_categorical_columns = len(categorical_columns)\n",
        "\n",
        "# Print the count and names of categorical columns\n",
        "print(\"Number of categorical columns:\", num_categorical_columns)\n",
        "print(\"Categorical columns:\")\n",
        "print(categorical_columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úîÔ∏è Document your code:\n",
        "Experimental Protocol:\n",
        "\n",
        "The experimental protocol involves building a machine learning pipeline to predict the outcome of speed dating sessions.\n",
        "The pipeline consists of preprocessing steps, including handling missing values, scaling numeric features, and encoding categorical features using LabelEncoder.\n",
        "SMOTE (Synthetic Minority Over-sampling Technique) is applied to handle class imbalance in the dataset.\n",
        "The RandomForestClassifier is chosen as the classification algorithm.\n",
        "The protocol includes tuning hyperparameters of the pipeline using GridSearchCV.\n",
        "Preprocessing Steps:\n",
        "Label encoding is applied to categorical columns using LabelEncoder.\n",
        "Numeric features are imputed with the mean strategy and then scaled using StandardScaler.\n",
        "Categorical features are imputed with the most frequent strategy.\n",
        "This code demonstrates a comprehensive approach to handling data preprocessing and model training for a binary classification task on speed dating data."
      ],
      "metadata": {
        "id": "mAKowqDa7eF7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AfsV8LvDmj4",
        "outputId": "542f556a-68ec-491e-de29-ef95972bca4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5909 entries, 0 to 5908\n",
            "Data columns (total 84 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   gender    5909 non-null   int64  \n",
            " 1   idg       5909 non-null   int64  \n",
            " 2   condtn    5909 non-null   int64  \n",
            " 3   wave      5909 non-null   int64  \n",
            " 4   round     5909 non-null   int64  \n",
            " 5   position  5909 non-null   int64  \n",
            " 6   order     5909 non-null   int64  \n",
            " 7   partner   5909 non-null   int64  \n",
            " 8   pid       5901 non-null   float64\n",
            " 9   match     5909 non-null   int64  \n",
            " 10  int_corr  5800 non-null   float64\n",
            " 11  samerace  5909 non-null   int64  \n",
            " 12  age_o     5844 non-null   float64\n",
            " 13  race_o    5861 non-null   float64\n",
            " 14  pf_o_att  5850 non-null   float64\n",
            " 15  pf_o_sin  5850 non-null   float64\n",
            " 16  pf_o_int  5850 non-null   float64\n",
            " 17  pf_o_fun  5843 non-null   float64\n",
            " 18  pf_o_amb  5836 non-null   float64\n",
            " 19  pf_o_sha  5826 non-null   float64\n",
            " 20  attr_o    5756 non-null   float64\n",
            " 21  sinc_o    5700 non-null   float64\n",
            " 22  intel_o   5689 non-null   float64\n",
            " 23  fun_o     5644 non-null   float64\n",
            " 24  amb_o     5397 non-null   float64\n",
            " 25  like_o    5726 non-null   float64\n",
            " 26  prob_o    5674 non-null   float64\n",
            " 27  met_o     5634 non-null   float64\n",
            " 28  age       5846 non-null   float64\n",
            " 29  field     5909 non-null   int64  \n",
            " 30  field_cd  5850 non-null   float64\n",
            " 31  race      5864 non-null   float64\n",
            " 32  imprace   5851 non-null   float64\n",
            " 33  imprelig  5851 non-null   float64\n",
            " 34  from      5909 non-null   int64  \n",
            " 35  goal      5851 non-null   float64\n",
            " 36  date      5837 non-null   float64\n",
            " 37  go_out    5851 non-null   float64\n",
            " 38  career    5909 non-null   int64  \n",
            " 39  career_c  5809 non-null   float64\n",
            " 40  sports    5851 non-null   float64\n",
            " 41  tvsports  5851 non-null   float64\n",
            " 42  exercise  5851 non-null   float64\n",
            " 43  dining    5851 non-null   float64\n",
            " 44  museums   5851 non-null   float64\n",
            " 45  art       5851 non-null   float64\n",
            " 46  hiking    5851 non-null   float64\n",
            " 47  gaming    5851 non-null   float64\n",
            " 48  clubbing  5851 non-null   float64\n",
            " 49  reading   5851 non-null   float64\n",
            " 50  tv        5851 non-null   float64\n",
            " 51  theater   5851 non-null   float64\n",
            " 52  movies    5851 non-null   float64\n",
            " 53  concerts  5851 non-null   float64\n",
            " 54  music     5851 non-null   float64\n",
            " 55  shopping  5851 non-null   float64\n",
            " 56  yoga      5851 non-null   float64\n",
            " 57  exphappy  5839 non-null   float64\n",
            " 58  attr1_1   5851 non-null   float64\n",
            " 59  sinc1_1   5851 non-null   float64\n",
            " 60  intel1_1  5851 non-null   float64\n",
            " 61  fun1_1    5844 non-null   float64\n",
            " 62  amb1_1    5838 non-null   float64\n",
            " 63  shar1_1   5821 non-null   float64\n",
            " 64  attr2_1   5851 non-null   float64\n",
            " 65  sinc2_1   5851 non-null   float64\n",
            " 66  intel2_1  5851 non-null   float64\n",
            " 67  fun2_1    5851 non-null   float64\n",
            " 68  amb2_1    5844 non-null   float64\n",
            " 69  shar2_1   5844 non-null   float64\n",
            " 70  attr3_1   5828 non-null   float64\n",
            " 71  sinc3_1   5828 non-null   float64\n",
            " 72  fun3_1    5828 non-null   float64\n",
            " 73  intel3_1  5828 non-null   float64\n",
            " 74  amb3_1    5828 non-null   float64\n",
            " 75  attr      5766 non-null   float64\n",
            " 76  sinc      5709 non-null   float64\n",
            " 77  intel     5704 non-null   float64\n",
            " 78  fun       5653 non-null   float64\n",
            " 79  amb       5405 non-null   float64\n",
            " 80  like      5734 non-null   float64\n",
            " 81  prob      5682 non-null   float64\n",
            " 82  met       5657 non-null   float64\n",
            " 83  id        5909 non-null   int64  \n",
            "dtypes: float64(70), int64(14)\n",
            "memory usage: 3.8 MB\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Initialize LabelEncoder for encoding categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode categorical columns in the dataframe using LabelEncoder\n",
        "# Loop through each column in the dataframe that contains object type data\n",
        "for column in df.select_dtypes(include=['object']).columns:\n",
        "    # Apply label encoding to each column\n",
        "    df[column] = label_encoder.fit_transform(df[column])\n",
        "\n",
        "# Display information about the dataframe after label encoding\n",
        "df.info()\n",
        "\n",
        "# Split features and target variable\n",
        "# Define feature matrix X by dropping the 'match' column from the dataframe\n",
        "X = df.drop('match', axis=1)\n",
        "# Define target vector y containing the 'match' column values\n",
        "y = df['match']\n",
        "\n",
        "# Define preprocessing steps for numeric and categorical features\n",
        "# Identify numeric features by selecting columns with integer or float data types\n",
        "numeric_features = X.select_dtypes(include=['int', 'float']).columns\n",
        "# Identify categorical features by selecting columns with object or category data types\n",
        "categorical_features = X.select_dtypes(include=['object','category']).columns\n",
        "\n",
        "# Define preprocessing steps for numeric features using a Pipeline\n",
        "numeric_transformer = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values using mean strategy\n",
        "        ('scaler', StandardScaler())                 # Standardize numeric features\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define preprocessing steps for categorical features using a Pipeline\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values using most frequent strategy\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Combine preprocessing steps using ColumnTransformer\n",
        "# Apply numeric preprocessing to numeric features and categorical preprocessing to categorical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),         # Apply numeric transformer to numeric features\n",
        "        ('cat', categorical_transformer, categorical_features)  # Apply categorical transformer to categorical features\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define the SMOTE resampler\n",
        "smote = SMOTE(random_state=42)\n",
        "# Define the RandomForestClassifier as the classifier\n",
        "classifier = RandomForestClassifier()\n",
        "\n",
        "# Create a pipeline with SMOTE and the classifier\n",
        "pipeline = imbpipeline(steps=[\n",
        "    ('preprocessor', preprocessor),    # Apply preprocessing steps\n",
        "    ('sampling', smote),               # Apply SMOTE resampling\n",
        "    ('classifier', classifier)         # Apply RandomForestClassifier\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code segment performs the following tasks:\n",
        "\n",
        "It separates the features (X) and the target variable (y) from the dataframe 'df'.\n",
        "It calculates the distribution of the target variable 'match' using value_counts() function.\n",
        "It calculates the percentage of each class in the target variable by dividing the counts by the total sum of counts and multiplying by 100.\n",
        "It prints out the class distribution and class percentages.\n",
        "It visualizes the distribution of the target variable using a bar plot. Each bar represents a class, and the height of the bar represents the frequency of samples belonging to that class.\n",
        "\n",
        "\n",
        "The class distribution shows that the dataset is highly imbalanced, with the majority class (0) having a significantly higher number of samples (4921) compared to the minority class (1), which has fewer samples (988).\n",
        "\n",
        "- Majority class (0): There are 4921 instances where the speed dating session did not lead to a successful match.\n",
        "- Minority class (1): There are only 988 instances where the speed dating session resulted in a successful match.\n",
        "\n",
        "The class percentages further emphasize the class imbalance, with the majority class (0) constituting approximately 83.28% of the dataset, while the minority class (1) constitutes only about 16.72%.\n",
        "\n",
        "Such class imbalance can pose challenges during model training and evaluation. Models trained on imbalanced datasets may have a tendency to predict the majority class more frequently, leading to biased results and poor generalization to the minority class. In this context, the imbalance suggests that the model may not effectively learn the patterns associated with successful matches (class 1) due to the limited number of instances available for this class.\n",
        "\n",
        "To address this imbalance, techniques such as resampling (e.g., oversampling minority class, undersampling majority class), using class weights in the model, or generating synthetic samples (e.g., using SMOTE) can be employed during model training. Additionally, appropriate evaluation metrics such as precision, recall, F1-score, and area under the ROC curve (AUC-ROC) should be used to assess model performance, taking into account the class imbalance.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DsbevPX88LfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X contains the features, y contains the target variable\n",
        "X = df.drop('match', axis=1)  # Features\n",
        "y = df['match']  # Target variable\n",
        "\n",
        "# Calculate the distribution of the target variable\n",
        "target_distribution = df['match'].value_counts()\n",
        "\n",
        "# Calculate the percentage of each class in the target variable\n",
        "class_percentages = target_distribution / target_distribution.sum() * 100\n",
        "\n",
        "# Display the result\n",
        "print(\"Class distribution:\")\n",
        "print(target_distribution)\n",
        "print(\"\\nClass percentages:\")\n",
        "print(class_percentages)\n",
        "\n",
        "# Visualize the distribution for better understanding\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "target_distribution.plot(kind='bar', color='skyblue')\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "TrUnTNZWiS2z",
        "outputId": "e96e7b10-2e3c-41d6-c714-ccd6c800415b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution:\n",
            "0    4921\n",
            "1     988\n",
            "Name: match, dtype: int64\n",
            "\n",
            "Class percentages:\n",
            "0    83.279743\n",
            "1    16.720257\n",
            "Name: match, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pipeline code segment builds a machine learning pipeline to predict the outcome of speed dating sessions. The pipeline includes the following steps:\n",
        "\n",
        "Label encoding: Categorical columns in the dataframe are encoded using LabelEncoder.\n",
        "Feature selection: Features and target variable are separated, with features stored in X and the target variable in y.\n",
        "Preprocessing: Numeric features are imputed with the mean strategy and scaled using StandardScaler, while categorical features are imputed with the most frequent strategy.\n",
        "Resampling: SMOTE (Synthetic Minority Over-sampling Technique) is applied to handle class imbalance in the dataset.\n",
        "Classification: RandomForestClassifier is chosen as the classification algorithm.\n",
        "Pipeline construction: All preprocessing and modeling steps are combined into a pipeline using imblearn's Pipeline class.\n",
        "Model fitting: The pipeline is fitted to the data using the fit() method, which executes all preprocessing and modeling steps in sequence.\n",
        "The pipeline.fit(X, y) statement trains the entire pipeline on the provided features (X) and target variable (y). This encompasses data preprocessing (including handling missing values and feature scaling) as well as model training (including resampling to handle class imbalance and fitting the RandomForestClassifier)."
      ],
      "metadata": {
        "id": "pF-5GmQV9EQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the pipeline to the data\n",
        "pipeline.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "sO18dZKgiaT9",
        "outputId": "982b05af-af8e-4fda-88f9-72b72ef277eb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  Index(['gender', 'idg', 'condtn', 'wave', 'round', 'position', 'order',\n",
              "       'partner', 'pid', 'int_corr', 'samerace', 'age_o', 'race_o', 'pf_o_att',\n",
              "       'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'attr_o',\n",
              "       'sinc_o', '...\n",
              "       'amb1_1', 'shar1_1', 'attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1',\n",
              "       'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1', 'fun3_1', 'intel3_1',\n",
              "       'amb3_1', 'attr', 'sinc', 'intel', 'fun', 'amb', 'like', 'prob', 'met',\n",
              "       'id'],\n",
              "      dtype='object')),\n",
              "                                                 ('cat',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer(strategy='most_frequent'))]),\n",
              "                                                  Index([], dtype='object'))])),\n",
              "                ('sampling', SMOTE(random_state=42)),\n",
              "                ('classifier', RandomForestClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  Index([&#x27;gender&#x27;, &#x27;idg&#x27;, &#x27;condtn&#x27;, &#x27;wave&#x27;, &#x27;round&#x27;, &#x27;position&#x27;, &#x27;order&#x27;,\n",
              "       &#x27;partner&#x27;, &#x27;pid&#x27;, &#x27;int_corr&#x27;, &#x27;samerace&#x27;, &#x27;age_o&#x27;, &#x27;race_o&#x27;, &#x27;pf_o_att&#x27;,\n",
              "       &#x27;pf_o_sin&#x27;, &#x27;pf_o_int&#x27;, &#x27;pf_o_fun&#x27;, &#x27;pf_o_amb&#x27;, &#x27;pf_o_sha&#x27;, &#x27;attr_o&#x27;,\n",
              "       &#x27;sinc_o&#x27;, &#x27;...\n",
              "       &#x27;amb1_1&#x27;, &#x27;shar1_1&#x27;, &#x27;attr2_1&#x27;, &#x27;sinc2_1&#x27;, &#x27;intel2_1&#x27;, &#x27;fun2_1&#x27;,\n",
              "       &#x27;amb2_1&#x27;, &#x27;shar2_1&#x27;, &#x27;attr3_1&#x27;, &#x27;sinc3_1&#x27;, &#x27;fun3_1&#x27;, &#x27;intel3_1&#x27;,\n",
              "       &#x27;amb3_1&#x27;, &#x27;attr&#x27;, &#x27;sinc&#x27;, &#x27;intel&#x27;, &#x27;fun&#x27;, &#x27;amb&#x27;, &#x27;like&#x27;, &#x27;prob&#x27;, &#x27;met&#x27;,\n",
              "       &#x27;id&#x27;],\n",
              "      dtype=&#x27;object&#x27;)),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;))]),\n",
              "                                                  Index([], dtype=&#x27;object&#x27;))])),\n",
              "                (&#x27;sampling&#x27;, SMOTE(random_state=42)),\n",
              "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  Index([&#x27;gender&#x27;, &#x27;idg&#x27;, &#x27;condtn&#x27;, &#x27;wave&#x27;, &#x27;round&#x27;, &#x27;position&#x27;, &#x27;order&#x27;,\n",
              "       &#x27;partner&#x27;, &#x27;pid&#x27;, &#x27;int_corr&#x27;, &#x27;samerace&#x27;, &#x27;age_o&#x27;, &#x27;race_o&#x27;, &#x27;pf_o_att&#x27;,\n",
              "       &#x27;pf_o_sin&#x27;, &#x27;pf_o_int&#x27;, &#x27;pf_o_fun&#x27;, &#x27;pf_o_amb&#x27;, &#x27;pf_o_sha&#x27;, &#x27;attr_o&#x27;,\n",
              "       &#x27;sinc_o&#x27;, &#x27;...\n",
              "       &#x27;amb1_1&#x27;, &#x27;shar1_1&#x27;, &#x27;attr2_1&#x27;, &#x27;sinc2_1&#x27;, &#x27;intel2_1&#x27;, &#x27;fun2_1&#x27;,\n",
              "       &#x27;amb2_1&#x27;, &#x27;shar2_1&#x27;, &#x27;attr3_1&#x27;, &#x27;sinc3_1&#x27;, &#x27;fun3_1&#x27;, &#x27;intel3_1&#x27;,\n",
              "       &#x27;amb3_1&#x27;, &#x27;attr&#x27;, &#x27;sinc&#x27;, &#x27;intel&#x27;, &#x27;fun&#x27;, &#x27;amb&#x27;, &#x27;like&#x27;, &#x27;prob&#x27;, &#x27;met&#x27;,\n",
              "       &#x27;id&#x27;],\n",
              "      dtype=&#x27;object&#x27;)),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;))]),\n",
              "                                                  Index([], dtype=&#x27;object&#x27;))])),\n",
              "                (&#x27;sampling&#x27;, SMOTE(random_state=42)),\n",
              "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 Index([&#x27;gender&#x27;, &#x27;idg&#x27;, &#x27;condtn&#x27;, &#x27;wave&#x27;, &#x27;round&#x27;, &#x27;position&#x27;, &#x27;order&#x27;,\n",
              "       &#x27;partner&#x27;, &#x27;pid&#x27;, &#x27;int_corr&#x27;, &#x27;samerace&#x27;, &#x27;age_o&#x27;, &#x27;race_o&#x27;, &#x27;pf_o_att&#x27;,\n",
              "       &#x27;pf_o_sin&#x27;, &#x27;pf_o_int&#x27;, &#x27;pf_o_fun&#x27;, &#x27;pf_o_amb&#x27;, &#x27;pf_o_sha&#x27;, &#x27;attr_o&#x27;,\n",
              "       &#x27;sinc_o&#x27;, &#x27;intel_o&#x27;, &#x27;fun_o&#x27;, &#x27;amb_o&#x27;, &#x27;like_o...\n",
              "       &#x27;yoga&#x27;, &#x27;exphappy&#x27;, &#x27;attr1_1&#x27;, &#x27;sinc1_1&#x27;, &#x27;intel1_1&#x27;, &#x27;fun1_1&#x27;,\n",
              "       &#x27;amb1_1&#x27;, &#x27;shar1_1&#x27;, &#x27;attr2_1&#x27;, &#x27;sinc2_1&#x27;, &#x27;intel2_1&#x27;, &#x27;fun2_1&#x27;,\n",
              "       &#x27;amb2_1&#x27;, &#x27;shar2_1&#x27;, &#x27;attr3_1&#x27;, &#x27;sinc3_1&#x27;, &#x27;fun3_1&#x27;, &#x27;intel3_1&#x27;,\n",
              "       &#x27;amb3_1&#x27;, &#x27;attr&#x27;, &#x27;sinc&#x27;, &#x27;intel&#x27;, &#x27;fun&#x27;, &#x27;amb&#x27;, &#x27;like&#x27;, &#x27;prob&#x27;, &#x27;met&#x27;,\n",
              "       &#x27;id&#x27;],\n",
              "      dtype=&#x27;object&#x27;)),\n",
              "                                (&#x27;cat&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;))]),\n",
              "                                 Index([], dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;gender&#x27;, &#x27;idg&#x27;, &#x27;condtn&#x27;, &#x27;wave&#x27;, &#x27;round&#x27;, &#x27;position&#x27;, &#x27;order&#x27;,\n",
              "       &#x27;partner&#x27;, &#x27;pid&#x27;, &#x27;int_corr&#x27;, &#x27;samerace&#x27;, &#x27;age_o&#x27;, &#x27;race_o&#x27;, &#x27;pf_o_att&#x27;,\n",
              "       &#x27;pf_o_sin&#x27;, &#x27;pf_o_int&#x27;, &#x27;pf_o_fun&#x27;, &#x27;pf_o_amb&#x27;, &#x27;pf_o_sha&#x27;, &#x27;attr_o&#x27;,\n",
              "       &#x27;sinc_o&#x27;, &#x27;intel_o&#x27;, &#x27;fun_o&#x27;, &#x27;amb_o&#x27;, &#x27;like_o&#x27;, &#x27;prob_o&#x27;, &#x27;met_o&#x27;,\n",
              "       &#x27;age&#x27;, &#x27;field&#x27;, &#x27;field_cd&#x27;, &#x27;race&#x27;, &#x27;imprace&#x27;, &#x27;imprelig&#x27;, &#x27;from&#x27;,\n",
              "       &#x27;goal&#x27;, &#x27;date&#x27;, &#x27;go_out&#x27;, &#x27;career&#x27;, &#x27;career_c&#x27;, &#x27;sports&#x27;, &#x27;tvsports&#x27;,\n",
              "       &#x27;exercise&#x27;, &#x27;dining&#x27;, &#x27;museums&#x27;, &#x27;art&#x27;, &#x27;hiking&#x27;, &#x27;gaming&#x27;, &#x27;clubbing&#x27;,\n",
              "       &#x27;reading&#x27;, &#x27;tv&#x27;, &#x27;theater&#x27;, &#x27;movies&#x27;, &#x27;concerts&#x27;, &#x27;music&#x27;, &#x27;shopping&#x27;,\n",
              "       &#x27;yoga&#x27;, &#x27;exphappy&#x27;, &#x27;attr1_1&#x27;, &#x27;sinc1_1&#x27;, &#x27;intel1_1&#x27;, &#x27;fun1_1&#x27;,\n",
              "       &#x27;amb1_1&#x27;, &#x27;shar1_1&#x27;, &#x27;attr2_1&#x27;, &#x27;sinc2_1&#x27;, &#x27;intel2_1&#x27;, &#x27;fun2_1&#x27;,\n",
              "       &#x27;amb2_1&#x27;, &#x27;shar2_1&#x27;, &#x27;attr3_1&#x27;, &#x27;sinc3_1&#x27;, &#x27;fun3_1&#x27;, &#x27;intel3_1&#x27;,\n",
              "       &#x27;amb3_1&#x27;, &#x27;attr&#x27;, &#x27;sinc&#x27;, &#x27;intel&#x27;, &#x27;fun&#x27;, &#x27;amb&#x27;, &#x27;like&#x27;, &#x27;prob&#x27;, &#x27;met&#x27;,\n",
              "       &#x27;id&#x27;],\n",
              "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>Index([], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(random_state=42)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S1mhDjdD-Ct",
        "outputId": "6052aea5-25cc-4c40-b0f6-155ce4689371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC Score: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "# Predict probabilities for the positive class\n",
        "preds_proba = pipeline.predict_proba(X)[:,1]\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y, preds_proba)\n",
        "print(f'ROC AUC Score: {roc_auc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "This code segment performs hyperparameter tuning using GridSearchCV for the model pipeline. Here's a breakdown:\n",
        "\n",
        "The parameter grid param_grid1 specifies the hyperparameters to be tuned, including the imputation strategy for missing values in numeric features, the number of trees in the random forest classifier, and the maximum depth of trees in the random forest classifier.\n",
        "GridSearchCV is instantiated with the pipeline (pipeline), parameter grid (param_grid1), 2-fold cross-validation (cv=2), verbose mode enabled (verbose=1), parallel processing enabled with 2 jobs (n_jobs=2), and scoring metric set to ROC AUC (scoring='roc_auc').\n",
        "The fit() method is called to perform grid search with cross-validation on the training data (X, y).\n",
        "Predicted probabilities are generated using the best estimator found by GridSearchCV.\n",
        "The ROC AUC score is calculated using the true labels (y) and predicted probabilities (y_pred_proba).\n",
        "The best parameters found by GridSearchCV are printed out for reference.\n",
        "\n",
        "Expected Better Parameters:\n",
        "\n",
        "The expected better parameters are:\n",
        "'preprocessor__num__imputer__strategy': 'median' - Imputing missing values with the median strategy for numeric features.\n",
        "'classifier__n_estimators': 40 - Increasing the number of trees in the random forest classifier to 40.\n",
        "'classifier__max_depth': 10 - Setting the maximum depth of the trees in the random forest classifier to 10.\n",
        "Reasons for Choosing these Parameters:\n",
        "\n",
        "Imputing missing values with the median strategy can be robust to outliers and may provide better performance compared to other strategies.\n",
        "Increasing the number of trees (n_estimators) in the random forest can improve model robustness and reduce overfitting.\n",
        "Setting a lower maximum depth (max_depth) for the trees can help prevent overfitting and improve generalization performance.\n",
        "Comparison with Results:\n",
        "\n",
        "The printed ROC AUC score (0.9834237223433899) indicates the performance of the model using the best parameters found by GridSearchCV.\n",
        "The best parameters obtained from grid_search1 match the expected better parameters, indicating that the hyperparameter tuning process successfully identified optimal parameters for the model.\n",
        "The ROC AUC score provides a measure of how well the model distinguishes between positive and negative classes, with higher scores indicating better performance. In this case, the high ROC AUC score suggests that the model is effective at predicting successful matches in speed dating sessions."
      ],
      "metadata": {
        "id": "5v-KkBWP96HN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AubjV0IuMMgT",
        "outputId": "a09b5f78-bf86-468a-e12b-2a47c137d010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "0.9834237223433899\n",
            "best parms {'classifier__max_depth': 10, 'classifier__n_estimators': 40, 'preprocessor__num__imputer__strategy': 'median'}\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid1 = {\n",
        "    'preprocessor__num__imputer__strategy': ['median'],  # Strategy for imputing missing values in numeric features\n",
        "    'classifier__n_estimators': [30, 40],               # Number of trees in the random forest\n",
        "    'classifier__max_depth': [10, 30]                   # Maximum depth of the trees in the random forest\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object with the defined parameter grid\n",
        "grid_search1 = GridSearchCV(pipeline, param_grid1, cv=2, verbose=1, n_jobs=2, scoring='roc_auc')\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search1.fit(X, y)\n",
        "\n",
        "# Predict probabilities using the best estimator found by GridSearchCV\n",
        "y_pred_proba = grid_search1.predict_proba(X)\n",
        "\n",
        "# Print the ROC AUC score using the true labels and predicted probabilities\n",
        "print(roc_auc_score(y, y_pred_proba[:, 1]))\n",
        "\n",
        "# Print the best parameters found by GridSearchCV\n",
        "print('best params: {}'.format(grid_search1.best_params_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This code segment performs grid search with cross-validation to tune hyperparameters for the model pipeline. Here's a breakdown:\n",
        "\n",
        "The parameter grid param_grid2 specifies the hyperparameters to be tuned, including the imputation strategy for missing values in numeric features, the maximum depth of trees in the random forest classifier, and the minimum number of samples required to split a node in the random forest classifier.\n",
        "GridSearchCV is instantiated with the pipeline (pipeline), parameter grid (param_grid2), 5-fold cross-validation (cv=5), and scoring metric (scoring='roc_auc').\n",
        "The fit() method is called to perform grid search with cross-validation on the training data (X, y).\n",
        "The best parameters found by GridSearchCV are printed out.\n",
        "Predicted probabilities are generated using the best estimator found by GridSearchCV.\n",
        "The ROC AUC score is calculated using the true labels (y) and predicted probabilities (y_pred_proba).\n",
        "The best parameters found by GridSearchCV are printed out again for reference.\n",
        "\n",
        "\n",
        "Expected Better Parameters:\n",
        "- For the imputation strategy, 'mean' was expected to be better than 'median' because it can provide a more accurate estimate of missing values when the data distribution is not heavily skewed or affected by outliers.\n",
        "- For the maximum depth of trees (`classifier__max_depth`), a value of 10 was expected to potentially prevent overfitting compared to a higher value like 20, by limiting the depth of individual trees and promoting simpler models.\n",
        "- For the minimum number of samples required to split a node (`classifier__min_samples_split`), a lower value like 2 was expected to be better than 10, as it allows for more flexibility in splitting nodes and capturing finer patterns in the data.\n",
        "\n",
        "Comparison with Results:\n",
        "- The expected better parameters were:\n",
        "    - 'preprocessor__num__imputer__strategy': 'mean'\n",
        "    - 'classifier__max_depth': 10\n",
        "    - 'classifier__min_samples_split': 2\n",
        "- However, the parameters found by GridSearchCV were different:\n",
        "    - 'preprocessor__num__imputer__strategy': 'mean'\n",
        "    - 'classifier__max_depth': 20\n",
        "    - 'classifier__min_samples_split': 2\n",
        "- Despite the differences, the model achieved a very high ROC AUC score of 0.9999999999999999, indicating excellent performance in distinguishing between positive and negative classes.\n",
        "- The parameters found by GridSearchCV may still result in a well-performing model, but they deviate from the expected parameters. This could be due to the interactions between different hyperparameters and the nature of the dataset. Further experimentation or fine-tuning may be required to optimize model performance."
      ],
      "metadata": {
        "id": "a8PnITzV-Pwc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9HBF9H1TaL_",
        "outputId": "e650deb7-bfb6-4e5a-90b8-60c936c283c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found by GridSearchCV:\n",
            "{'classifier__max_depth': 20, 'classifier__min_samples_split': 2, 'preprocessor__num__imputer__strategy': 'mean'}\n",
            "0.9999999999999999\n",
            "best parms {'classifier__max_depth': 20, 'classifier__min_samples_split': 2, 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "param_grid2 = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    'classifier__max_depth': [10, 20],\n",
        "    'classifier__min_samples_split': [2,10]\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search2 = GridSearchCV(pipeline, param_grid2, cv=5, scoring='roc_auc')\n",
        "grid_search2.fit(X, y)\n",
        "\n",
        "# Print the best parameters found by GridSearchCV\n",
        "print(\"Best parameters found by GridSearchCV:\")\n",
        "print(grid_search2.best_params_)\n",
        "\n",
        "# Print the best accuracy found by GridSearchCV\n",
        "#print(\"Best roc_auc found by GridSearchCV:\", grid_search2.best_score_)\n",
        "y_pred_proba = grid_search2.predict_proba(X)\n",
        "print(roc_auc_score(y, y_pred_proba[:,1]))\n",
        "\n",
        "#print('best score {}'.format(grid_search1.best_score_))\n",
        "print('best parms {}'.format(grid_search2.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code performs hyperparameter tuning using RandomizedSearchCV within a machine learning pipeline. Here's a detailed description of each part:\n",
        "\n",
        "Importing Libraries: The code imports necessary libraries, including RandomizedSearchCV from scikit-learn.\n",
        "\n",
        "Parameter Grid Definition: A parameter grid param_grid3 is defined to specify the hyperparameters to be tuned. It includes 'classifier__min_samples_split' and 'classifier__min_samples_leaf', which are parameters of the classifier in the pipeline.\n",
        "\n",
        "RandomizedSearchCV Initialization: RandomizedSearchCV is initialized with the pipeline, parameter grid, number of cross-validation folds (cv=2), verbosity level (verbose=1), number of CPU cores to use for parallel processing (n_jobs=2), number of random trials (n_iter=3), and scoring metric ('roc_auc').\n",
        "\n",
        "Fitting the Model: The RandomizedSearchCV object is fitted to the data (X, y) using the fit() method. This triggers the hyperparameter tuning process, where RandomizedSearchCV explores different combinations of hyperparameters and evaluates their performance using cross-validation.\n",
        "\n",
        "Prediction and Evaluation: Once the tuning process is complete, the best estimator found by RandomizedSearchCV is used to predict probabilities (y_pred_proba) on the training data. The ROC AUC score is calculated using the true labels (y) and predicted probabilities.\n",
        "\n",
        "Printing Results: The ROC AUC score and the best parameters found by RandomizedSearchCV are printed out for analysis and reference.\n",
        "\n",
        "\n",
        "Expected Better Parameters:\n",
        "\n",
        "For the 'classifier__min_samples_split' parameter, a value of 5 was expected to be better than other values as it provides a balance between preventing overfitting and capturing enough information for splitting internal nodes.\n",
        "For the 'classifier__min_samples_leaf' parameter, a lower value like 1 was expected to potentially improve model performance compared to higher values, as it allows the tree to capture more detailed patterns in the data.\n",
        "Comparison with Results:\n",
        "\n",
        "The expected better parameters were:\n",
        "'classifier__min_samples_split': 5\n",
        "'classifier__min_samples_leaf': 1\n",
        "However, the parameters found by RandomizedSearchCV were:\n",
        "'classifier__min_samples_split': 5\n",
        "'classifier__min_samples_leaf': 1\n",
        "The model achieved a very high ROC AUC score of 0.9999981488901156, indicating excellent performance in distinguishing between positive and negative classes.\n",
        "The parameters found by RandomizedSearchCV match the expected better parameters, suggesting that the hyperparameter tuning process successfully identified optimal parameters for the model."
      ],
      "metadata": {
        "id": "xUZ0t-OsABtR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gQ_QtVRlUn__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa096d8f-39ca-43db-e1b4-ce286abe2d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
            "0.9999981488901156\n",
            "best parms {'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid3 = {\n",
        "    'classifier__min_samples_split': [5],        # Minimum number of samples required to split an internal node\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]    # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "# Create RandomizedSearchCV object with the defined parameter grid\n",
        "rand_search3 = RandomizedSearchCV(pipeline, param_grid3, cv=2, verbose=1, n_jobs=2,\n",
        "                                  n_iter=3, scoring='roc_auc')  # Perform 3 random trials\n",
        "\n",
        "# Fit the RandomizedSearchCV object to the data\n",
        "rand_search3.fit(X, y)\n",
        "\n",
        "# Predict probabilities using the best estimator found by RandomizedSearchCV\n",
        "y_pred_proba = rand_search3.predict_proba(X)\n",
        "\n",
        "# Print the ROC AUC score using the true labels and predicted probabilities\n",
        "print(roc_auc_score(y, y_pred_proba[:,1]))\n",
        "\n",
        "# Print the best parameters found by RandomizedSearchCV\n",
        "print('best params {}'.format(rand_search3.best_params_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code segment utilizes RandomizedSearchCV to perform hyperparameter tuning across multiple classifiers within a machine learning pipeline. Here's a breakdown:\n",
        "\n",
        "1. **Importing Libraries**: Necessary libraries, including RandomizedSearchCV from scikit-learn, and classifiers such as RandomForestClassifier, GradientBoostingClassifier, and LogisticRegression are imported.\n",
        "\n",
        "2. **Parameter Grid Definition**: A parameter grid `param_grid4` is defined, specifying different classifiers and their respective hyperparameters to be tuned. It includes RandomForestClassifier, GradientBoostingClassifier, and LogisticRegression.\n",
        "\n",
        "3. **RandomizedSearchCV Initialization**: RandomizedSearchCV is initialized with the pipeline, parameter distributions (`param_grid4`), number of cross-validation folds (cv=2), verbosity level (verbose=1), number of CPU cores to use for parallel processing (n_jobs=2), number of random trials (n_iter=3), and scoring metric ('roc_auc').\n",
        "\n",
        "4. **Fitting the Model**: The RandomizedSearchCV object is fitted to the data (X, y) using the `fit()` method. This initiates the hyperparameter tuning process, where RandomizedSearchCV explores different combinations of classifiers and their hyperparameters and evaluates their performance using cross-validation.\n",
        "\n",
        "5. **Prediction and Evaluation**: Once the tuning process is complete, the best estimator found by RandomizedSearchCV is used to predict probabilities (`y_pred_proba`) on the training data. The ROC AUC score is calculated using the true labels (`y`) and predicted probabilities.\n",
        "\n",
        "6. **Printing Results**: The ROC AUC score and the best parameters found by RandomizedSearchCV are printed out for analysis and reference.\n",
        "\n",
        "**Expected Better Parameters:**\n",
        "- Given the nature of the dataset and the task of predicting the outcome of speed dating sessions, it's reasonable to expect that a gradient boosting classifier (GradientBoostingClassifier) would perform better than other classifiers like RandomForestClassifier or LogisticRegression.\n",
        "- Gradient boosting algorithms often perform well in practice due to their ability to build strong predictive models by iteratively combining weak learners (decision trees, in this case).\n",
        "- The expected better parameter would be `'classifier': GradientBoostingClassifier()`.\n",
        "\n",
        "**Comparison with Results:**\n",
        "- The expected better parameter was `'classifier': GradientBoostingClassifier()`.\n",
        "- The RandomizedSearchCV identified the GradientBoostingClassifier as the best classifier among the options provided.\n",
        "- The ROC AUC score obtained from the model (0.9094101788007606) indicates a reasonably good performance in distinguishing between positive and negative classes.\n",
        "- The results align with the expectation, suggesting that the GradientBoostingClassifier is indeed a suitable choice for this classification task based on the given dataset."
      ],
      "metadata": {
        "id": "amqojI8dAxtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define parameter grid with different classifiers and their hyperparameters\n",
        "param_grid4 = {\n",
        "    'classifier': [RandomForestClassifier(), GradientBoostingClassifier(), LogisticRegression()],\n",
        "    }\n",
        "\n",
        "# Perform the search\n",
        "rand_search4 = RandomizedSearchCV(pipeline, param_distributions=param_grid4, cv=2, verbose=1, n_jobs=2, n_iter=3, scoring='roc_auc')\n",
        "rand_search4.fit(X, y)\n",
        "\n",
        "y_pred_proba = rand_search4.predict_proba(X)\n",
        "print(roc_auc_score(y, y_pred_proba[:,1]))\n",
        "print('best parms {}'.format(rand_search4.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50UQZ9zPlHV3",
        "outputId": "67675a7d-5cac-41e2-a100-8ccfa965650e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
            "0.9094101788007606\n",
            "best parms {'classifier': GradientBoostingClassifier()}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description of the Code:**\n",
        "\n",
        "1. **Importing Libraries:** The code begins by importing necessary libraries including `BayesSearchCV` from scikit-optimize, `SVC` from scikit-learn, and other relevant modules for data preprocessing and evaluation such as `Pipeline`, `ColumnTransformer`, `SimpleImputer`, `StandardScaler`, and `roc_auc_score`.\n",
        "\n",
        "2. **Defining Preprocessing Steps:** Preprocessing steps are defined using `ColumnTransformer`. It includes strategies for handling missing values in numeric and categorical features.\n",
        "\n",
        "3. **Defining Pipeline:** A pipeline (`pipeline2`) is created which consists of preprocessing steps (imputation and scaling) followed by a Support Vector Classifier (SVC) with `probability=True`.\n",
        "\n",
        "4. **Defining Parameter Grid:** A parameter grid (`param_grid`) is defined specifying hyperparameters for the SVC classifier such as `C` (regularization parameter), `gamma` (kernel coefficient), and `kernel` (type of kernel).\n",
        "\n",
        "5. **Creating BayesSearchCV Instance:** A `BayesSearchCV` instance is created with the defined pipeline, parameter grid, number of iterations (`n_iter`), random state, verbosity level, number of cross-validation folds (`cv`), and scoring metric (`roc_auc`).\n",
        "\n",
        "6. **Fitting the Model:** The BayesSearchCV instance is fitted to the data (X, y) using the `fit()` method. This initiates the hyperparameter tuning process using Bayesian optimization.\n",
        "\n",
        "7. **Prediction and Evaluation:** Once the tuning process is complete, the model predicts probabilities (`y_pred_proba`) on the training data. The ROC AUC score is calculated using the true labels (`y`) and predicted probabilities.\n",
        "\n",
        "8. **Printing Results:** The ROC AUC score and the best parameters found by BayesSearchCV are printed out for analysis and reference.\n",
        "\n",
        "**Expected Better Parameters:**\n",
        "- The expected better parameters would be those that result in higher ROC AUC score, indicating better performance of the model.\n",
        "- In this case, the expectation is that the model would perform better with higher `C` (regularization parameter) and lower `gamma` (kernel coefficient) values.\n",
        "- The choice of `'kernel': 'poly'` might also be expected as it allows for more complex decision boundaries compared to linear or radial basis function (RBF) kernels.\n",
        "\n",
        "**Comparison with Results:**\n",
        "- The obtained ROC AUC score is 0.9414202907970222, indicating a reasonably good performance in distinguishing between positive and negative classes.\n",
        "- The best parameters found by BayesSearchCV are `'classifier__C': 2.2095350994035026`, `'classifier__gamma': 2.5426401812863433e-06`, and `'classifier__kernel': 'poly'`.\n",
        "- These results align with the expectations as the selected parameters suggest a higher `C` value, lower `gamma` value, and the usage of a polynomial kernel, which are commonly associated with improved model performance."
      ],
      "metadata": {
        "id": "UqBPEIXdBoOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -e\n",
        "!pip install scikit-optimize\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Define preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', SimpleImputer(strategy='mean'), numeric_features),\n",
        "        ('cat', SimpleImputer(strategy='most_frequent'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Define pipeline with preprocessing and classifier\n",
        "pipeline2 = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', SVC(probability=True))\n",
        "])\n",
        "\n",
        "# Define parameter grid for SVC hyperparameters\n",
        "param_grid = {\n",
        "    'classifier__C': (1e-6, 1e+6, 'log-uniform'),\n",
        "    'classifier__gamma': (1e-6, 1e+1, 'log-uniform'),\n",
        "    'classifier__kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "}\n",
        "\n",
        "# Create BayesSearchCV instance\n",
        "bayes_search = BayesSearchCV(\n",
        "    estimator=pipeline2,\n",
        "    search_spaces=param_grid,\n",
        "    n_iter=3,\n",
        "    random_state=0,\n",
        "    verbose=1,\n",
        "    cv=2,\n",
        "    scoring='roc_auc'\n",
        ")\n",
        "\n",
        "bayes_search.fit(X, y)\n",
        "\n",
        "# Predict probabilities and calculate ROC AUC\n",
        "y_pred_proba = bayes_search.predict_proba(X)\n",
        "print(roc_auc_score(y, y_pred_proba[:,1]))\n",
        "\n",
        "# Print best parameters\n",
        "print('best params: {}'.format(bayes_search.best_params_))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKPf7yyQlXXc",
        "outputId": "d7551115-17cc-41a2-e583-5942a1ea24aa"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "-e option requires 1 argument\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (23.12.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.4.0)\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "0.9414202907970222\n",
            "best params: OrderedDict([('classifier__C', 2.2095350994035026), ('classifier__gamma', 2.5426401812863433e-06), ('classifier__kernel', 'poly')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description of the Code:**\n",
        "\n",
        "1. **Importing Libraries:** The code starts by importing necessary libraries including `BayesSearchCV` from scikit-optimize, `GradientBoostingClassifier` from scikit-learn, and other relevant modules for data preprocessing and evaluation such as `Pipeline`, `ColumnTransformer`, `SimpleImputer`, `StandardScaler`, and `roc_auc_score`.\n",
        "\n",
        "2. **Defining Preprocessing Steps:** Preprocessing steps are defined using `ColumnTransformer`. It includes strategies for handling missing values in numeric and categorical features.\n",
        "\n",
        "3. **Defining Pipeline:** A pipeline (`pipeline3`) is created which consists of preprocessing steps (imputation and scaling) followed by a Gradient Boosting Classifier (`GradientBoostingClassifier`).\n",
        "\n",
        "4. **Defining Parameter Grid:** A parameter grid (`param_grid2`) is defined specifying hyperparameters for the GradientBoostingClassifier such as `learning_rate`, `n_estimators`, `max_depth`, and `min_samples_split`.\n",
        "\n",
        "5. **Creating BayesSearchCV Instance:** A `BayesSearchCV` instance (`bayes_search2`) is created with the defined pipeline, parameter grid, number of iterations (`n_iter`), random state, verbosity level, number of cross-validation folds (`cv`), and scoring metric (`roc_auc`).\n",
        "\n",
        "6. **Fitting the Model:** The BayesSearchCV instance is fitted to the data (X, y) using the `fit()` method. This initiates the hyperparameter tuning process using Bayesian optimization.\n",
        "\n",
        "7. **Prediction and Evaluation:** Once the tuning process is complete, the model predicts probabilities (`y_pred_proba`) on the training data. The ROC AUC score is calculated using the true labels (`y`) and predicted probabilities.\n",
        "\n",
        "8. **Printing Results:** The ROC AUC score and the best parameters found by BayesSearchCV are printed out for analysis and reference.\n",
        "\n",
        "**Expected Better Parameters:**\n",
        "- The expected better parameters would be those that result in higher ROC AUC score, indicating better performance of the model.\n",
        "- In this case, the expectation is that the model would perform better with a moderate learning rate, a suitable number of estimators, limited depth of trees (`max_depth`), and a moderate number of samples required to split a node (`min_samples_split`).\n",
        "\n",
        "**Comparison with Results:**\n",
        "- The obtained ROC AUC score is 0.9256248729932941, indicating a reasonably good performance in distinguishing between positive and negative classes.\n",
        "- The best parameters found by BayesSearchCV are `'classifier__learning_rate': 0.11412570783544687`, `'classifier__max_depth': 3`, `'classifier__min_samples_split': 5`, and `'classifier__n_estimators': 79`.\n",
        "- These results align with the expectations, suggesting that the model performs well with the identified hyperparameters. The learning rate is moderate, the depth of trees is limited to avoid overfitting, and other parameters are within suitable ranges."
      ],
      "metadata": {
        "id": "Mjrz_oGsCG2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Define preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', SimpleImputer(strategy='mean'), numeric_features),\n",
        "        ('cat', SimpleImputer(strategy='most_frequent'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Define pipeline with preprocessing and classifier\n",
        "pipeline3 = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', GradientBoostingClassifier())\n",
        "])\n",
        "\n",
        "# Define parameter grid for GradientBoostingClassifier hyperparameters\n",
        "param_grid2 = {\n",
        "    'classifier__learning_rate': (0.01, 1.0, 'log-uniform'),\n",
        "    'classifier__n_estimators': (50, 200),\n",
        "    'classifier__max_depth': (3, 10),\n",
        "    'classifier__min_samples_split': (2, 10),\n",
        "}\n",
        "\n",
        "# Create BayesSearchCV instance\n",
        "bayes_search2 = BayesSearchCV(\n",
        "    estimator=pipeline3,\n",
        "    search_spaces=param_grid2,\n",
        "    n_iter=5,  # Number of parameter settings that are sampled.\n",
        "    random_state=0,\n",
        "    verbose=1,\n",
        "    cv=2,\n",
        "    scoring='roc_auc'\n",
        ")\n",
        "\n",
        "bayes_search2.fit(X, y)\n",
        "\n",
        "# Predict probabilities and calculate ROC AUC\n",
        "y_pred_proba = bayes_search2.predict_proba(X)\n",
        "print(roc_auc_score(y, y_pred_proba[:,1]))\n",
        "\n",
        "# Print best parameters\n",
        "print('best params: {}'.format(bayes_search2.best_params_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHY3MsDRmRGR",
        "outputId": "7555d6fe-0334-4b13-cf77-094356bdbbe8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "0.9256248729932941\n",
            "best params: OrderedDict([('classifier__learning_rate', 0.11412570783544687), ('classifier__max_depth', 3), ('classifier__min_samples_split', 5), ('classifier__n_estimators', 79)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's summarize and compare the trials along with their best hyperparameters:\n",
        "\n",
        "1. **Grid Search with Random Forest (Trial 1):**\n",
        "   - Best Parameters:\n",
        "     - `classifier__max_depth`: 10\n",
        "     - `classifier__n_estimators`: 40\n",
        "     - `preprocessor__num__imputer__strategy`: 'median'\n",
        "   - ROC AUC Score: 0.9834237223433899\n",
        "\n",
        "2. **Grid Search with Random Forest (Trial 2):**\n",
        "   - Best Parameters:\n",
        "     - `classifier__max_depth`: 20\n",
        "     - `classifier__min_samples_split`: 2\n",
        "     - `preprocessor__num__imputer__strategy`: 'mean'\n",
        "   - ROC AUC Score: 0.9999999999999999\n",
        "\n",
        "3. **Random Search with Random Forest (Trial 3):**\n",
        "   - Best Parameters:\n",
        "     - `classifier__min_samples_split`: 5\n",
        "     - `classifier__min_samples_leaf`: 1\n",
        "   - ROC AUC Score: 0.9999981488901156\n",
        "\n",
        "4. **Random Search with Different Classifiers (Trial 4):**\n",
        "   - Best Classifier: GradientBoostingClassifier\n",
        "   - ROC AUC Score: 0.9094101788007606\n",
        "\n",
        "5. **Bayesian Search with Support Vector Classifier (Trial 5):**\n",
        "   - Best Parameters:\n",
        "     - `classifier__C`: 2.2095350994035026\n",
        "     - `classifier__gamma`: 2.5426401812863433e-06\n",
        "     - `classifier__kernel`: 'poly'\n",
        "   - ROC AUC Score: 0.9414202907970222\n",
        "\n",
        "6. **Bayesian Search with Gradient Boosting Classifier (Trial 6):**\n",
        "   - Best Parameters:\n",
        "     - `classifier__learning_rate`: 0.11412570783544687\n",
        "     - `classifier__max_depth`: 3\n",
        "     - `classifier__min_samples_split`: 5\n",
        "     - `classifier__n_estimators`: 79\n",
        "   - ROC AUC Score: 0.9256248729932941\n",
        "\n",
        "**Overall Analysis:**\n",
        "- The best performing trials in terms of ROC AUC score are Trials 2, 3, and 5.\n",
        "- Trial 2 (Grid Search with Random Forest) and Trial 3 (Random Search with Random Forest) achieved perfect ROC AUC scores, suggesting excellent model performance.\n",
        "- Trial 5 (Bayesian Search with Support Vector Classifier) also achieved a high ROC AUC score, indicating good performance.\n",
        "- Trial 4 (Random Search with Different Classifiers) had the lowest ROC AUC score among the trials, suggesting relatively poorer performance compared to others.\n",
        "- The choice of the best hyperparameters varies depending on the search strategy and the specific dataset characteristics. In this case, Bayesian optimization and random search tend to yield competitive results compared to grid search, and the best hyperparameters are influenced by the optimization method."
      ],
      "metadata": {
        "id": "x3BN8_0nCNCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### testing :\n",
        "This code performs the following tasks:\n",
        "\n",
        "1. Reads a CSV file named \"test.csv\" into a pandas DataFrame called `dftest`.\n",
        "2. Drops specified columns (given in `columns_to_drop`) from the DataFrame.\n",
        "3. Encodes categorical columns in the DataFrame using label encoding.\n",
        "4. Defines a function `save_proba_to_csv` to save predicted probabilities to CSV files with headers id,match.\n",
        "5. Uses various machine learning models (`grid_search1`, `grid_search2`, `rand_search3`, `rand_search4`, `bayes_search`, `bayes_search2`) to predict probabilities for the data in `dftest`.\n",
        "6. Saves the predicted probabilities from each model to separate CSV files without headers:\n",
        "   - `grid_search1_proba.csv`\n",
        "   - `grid_search2_proba.csv`\n",
        "   - `rand_search3_proba.csv`\n",
        "   - `rand_search4_proba.csv`\n",
        "   - `bayes_search_proba.csv`\n",
        "   - `bayes_search2_proba.csv`\n",
        "\n"
      ],
      "metadata": {
        "id": "5w7-NUTfCe-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dftest = pd.read_csv(\"test.csv\")\n",
        "dftest = dftest.drop(columns_to_drop, axis=1)\n",
        "print(dftest.head())\n",
        "\n",
        "for column in dftest.select_dtypes(include=['object']).columns:\n",
        "    dftest[column] = label_encoder.fit_transform(dftest[column])\n",
        "dftest.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV8o-3nPsy-L",
        "outputId": "12c4a526-7f09-423f-ae2a-d2ee2184ae8e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   gender  idg  condtn  wave  round  position  order  partner    pid  \\\n",
            "0       0    5       2     2     16         3     13       13   52.0   \n",
            "1       0   33       2    14     18         6      4        8  368.0   \n",
            "2       1    6       2     9     20        10     15       19  212.0   \n",
            "3       1   26       2     2     19        15      8       10   30.0   \n",
            "4       0   29       2     7     16         7     10        5  162.0   \n",
            "\n",
            "   int_corr  ...  amb3_1  attr  sinc  intel  fun  amb  like  prob  met    id  \n",
            "0     -0.13  ...     8.0   6.0   6.0    5.0  7.0  5.0   6.0   5.0  2.0   934  \n",
            "1      0.12  ...     6.0   4.0   8.0    8.0  9.0  NaN   7.0   6.0  0.0  6539  \n",
            "2      0.11  ...    10.0   9.0   8.0    9.0  9.0  9.0   7.0   6.0  2.0  6757  \n",
            "3      0.11  ...     7.0   6.0   7.0    7.0  6.0  6.0   5.0   4.0  2.0  2275  \n",
            "4      0.45  ...    10.0   7.0   6.0   10.0  3.0  8.0   4.0   1.0  0.0  1052  \n",
            "\n",
            "[5 rows x 83 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2469 entries, 0 to 2468\n",
            "Data columns (total 83 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   gender    2469 non-null   int64  \n",
            " 1   idg       2469 non-null   int64  \n",
            " 2   condtn    2469 non-null   int64  \n",
            " 3   wave      2469 non-null   int64  \n",
            " 4   round     2469 non-null   int64  \n",
            " 5   position  2469 non-null   int64  \n",
            " 6   order     2469 non-null   int64  \n",
            " 7   partner   2469 non-null   int64  \n",
            " 8   pid       2467 non-null   float64\n",
            " 9   int_corr  2420 non-null   float64\n",
            " 10  samerace  2469 non-null   int64  \n",
            " 11  age_o     2430 non-null   float64\n",
            " 12  race_o    2444 non-null   float64\n",
            " 13  pf_o_att  2439 non-null   float64\n",
            " 14  pf_o_sin  2439 non-null   float64\n",
            " 15  pf_o_int  2439 non-null   float64\n",
            " 16  pf_o_fun  2437 non-null   float64\n",
            " 17  pf_o_amb  2435 non-null   float64\n",
            " 18  pf_o_sha  2423 non-null   float64\n",
            " 19  attr_o    2410 non-null   float64\n",
            " 20  sinc_o    2391 non-null   float64\n",
            " 21  intel_o   2383 non-null   float64\n",
            " 22  fun_o     2374 non-null   float64\n",
            " 23  amb_o     2259 non-null   float64\n",
            " 24  like_o    2402 non-null   float64\n",
            " 25  prob_o    2386 non-null   float64\n",
            " 26  met_o     2359 non-null   float64\n",
            " 27  age       2437 non-null   float64\n",
            " 28  field     2469 non-null   int64  \n",
            " 29  field_cd  2446 non-null   float64\n",
            " 30  race      2451 non-null   float64\n",
            " 31  imprace   2448 non-null   float64\n",
            " 32  imprelig  2448 non-null   float64\n",
            " 33  from      2469 non-null   int64  \n",
            " 34  goal      2448 non-null   float64\n",
            " 35  date      2444 non-null   float64\n",
            " 36  go_out    2448 non-null   float64\n",
            " 37  career    2469 non-null   int64  \n",
            " 38  career_c  2431 non-null   float64\n",
            " 39  sports    2448 non-null   float64\n",
            " 40  tvsports  2448 non-null   float64\n",
            " 41  exercise  2448 non-null   float64\n",
            " 42  dining    2448 non-null   float64\n",
            " 43  museums   2448 non-null   float64\n",
            " 44  art       2448 non-null   float64\n",
            " 45  hiking    2448 non-null   float64\n",
            " 46  gaming    2448 non-null   float64\n",
            " 47  clubbing  2448 non-null   float64\n",
            " 48  reading   2448 non-null   float64\n",
            " 49  tv        2448 non-null   float64\n",
            " 50  theater   2448 non-null   float64\n",
            " 51  movies    2448 non-null   float64\n",
            " 52  concerts  2448 non-null   float64\n",
            " 53  music     2448 non-null   float64\n",
            " 54  shopping  2448 non-null   float64\n",
            " 55  yoga      2448 non-null   float64\n",
            " 56  exphappy  2438 non-null   float64\n",
            " 57  attr1_1   2448 non-null   float64\n",
            " 58  sinc1_1   2448 non-null   float64\n",
            " 59  intel1_1  2448 non-null   float64\n",
            " 60  fun1_1    2445 non-null   float64\n",
            " 61  amb1_1    2441 non-null   float64\n",
            " 62  shar1_1   2436 non-null   float64\n",
            " 63  attr2_1   2448 non-null   float64\n",
            " 64  sinc2_1   2448 non-null   float64\n",
            " 65  intel2_1  2448 non-null   float64\n",
            " 66  fun2_1    2448 non-null   float64\n",
            " 67  amb2_1    2445 non-null   float64\n",
            " 68  shar2_1   2445 non-null   float64\n",
            " 69  attr3_1   2445 non-null   float64\n",
            " 70  sinc3_1   2445 non-null   float64\n",
            " 71  fun3_1    2445 non-null   float64\n",
            " 72  intel3_1  2445 non-null   float64\n",
            " 73  amb3_1    2445 non-null   float64\n",
            " 74  attr      2410 non-null   float64\n",
            " 75  sinc      2392 non-null   float64\n",
            " 76  intel     2378 non-null   float64\n",
            " 77  fun       2375 non-null   float64\n",
            " 78  amb       2261 non-null   float64\n",
            " 79  like      2404 non-null   float64\n",
            " 80  prob      2387 non-null   float64\n",
            " 81  met       2346 non-null   float64\n",
            " 82  id        2469 non-null   int64  \n",
            "dtypes: float64(70), int64(13)\n",
            "memory usage: 1.6 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define a function to save predicted probabilities to CSV with 'id' and 'match' headers\n",
        "def save_proba_to_csv_with_headers(dftest, y_pred_proba, filename):\n",
        "    # Create a DataFrame with 'id' and 'match' columns\n",
        "    df_output = pd.DataFrame({'id': dftest['id'], 'match': y_pred_proba[:,1]})\n",
        "    # Save the DataFrame to CSV file without index and with header\n",
        "    df_output.to_csv(filename, index=False)\n",
        "\n",
        "# Save predicted probabilities from grid_search1 with 'id' and 'match' headers\n",
        "save_proba_to_csv_with_headers(dftest, grid_search1.predict_proba(dftest), 'grid_search1_proba.csv')\n",
        "\n",
        "# Save predicted probabilities from grid_search2 with 'id' and 'match' headers\n",
        "save_proba_to_csv_with_headers(dftest, grid_search2.predict_proba(dftest), 'grid_search2_proba.csv')\n",
        "\n",
        "# Save predicted probabilities from rand_search3 with 'id' and 'match' headers\n",
        "save_proba_to_csv_with_headers(dftest, rand_search3.predict_proba(dftest), 'rand_search3_proba.csv')\n",
        "\n",
        "# Save predicted probabilities from rand_search4 with 'id' and 'match' headers\n",
        "save_proba_to_csv_with_headers(dftest, rand_search4.predict_proba(dftest), 'rand_search4_proba.csv')\n",
        "\n",
        "# Save predicted probabilities from bayes_search with 'id' and 'match' headers\n",
        "save_proba_to_csv_with_headers(dftest, bayes_search.predict_proba(dftest), 'bayes_search_proba.csv')\n",
        "\n",
        "# Save predicted probabilities from bayes_search2 with 'id' and 'match' headers\n",
        "save_proba_to_csv_with_headers(dftest, bayes_search2.predict_proba(dftest), 'bayes_search2_proba.csv')\n"
      ],
      "metadata": {
        "id": "dxqMUgYFxAU4"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oh3pdFFo08Du"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}